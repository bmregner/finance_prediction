{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Predicting financial indicators is definitely a holy grail for our society at its present stage. There is a vast literature on how to do this and the general approach is a time-series one, that is, predict the future of one quantity based on that quantity's past.\n",
    "\n",
    "We are trying to see if it's possible to complement this approach with data coming from news sources, reasoning that news from the world should directly and indirectly weigh on the performance of such indicators as stocks, employment rate, or inflation.\n",
    "\n",
    "Please keep in mind that we do not expect to make any significant improvement over state-of-the-art financial analyses (which involve much more complex and refined models). Rather, we are interested in building a scalable and dynamic pipeline that in the future might supplement those already-existing models or give interesting insights.\n",
    "\n",
    "### This notebook\n",
    "\n",
    "This is a walkthrough illustrating the typical usage of our package. We will try to predict future S&P500 closing values based on past S&P500 values along with NLP features extracted from the daily-updted GDELT 1.0 (http://www.gdeltproject.org/) event database.\n",
    "\n",
    "In particular, to scope down the analysis to a minimally viable scalable pipeline, I extract features from the source urls contained in the database (one associated to each event).\n",
    "\n",
    "For each day, all urls get parsed, tokenized, and stemmed, and then conflated together into a single bag of words. This will constitute one document. After that I may apply a tf-idf or word2vec vectorization (this latter being much favored).\n",
    "\n",
    "I use the extracted features (plus the same day's closing S&P500) to try and fit various regression models to predict the next day's S&P500 and compare them to a benchmark model (a simple naive model predicting the same for tomorrow as today, plus the average increase or decrease over the last few days).\n",
    "\n",
    "I also try to predict if tomorrow's index value will rise or fall, given today's news.\n",
    "\n",
    "For both tasks random forest regressors/classifiers seem promising approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "sourcedir=os.getcwd()+\"/../source\"\n",
    "if sourcedir not in sys.path:\n",
    "    sys.path.append(sourcedir)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_training' from '/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing our nlp proprocessing module, the reload command is for development\n",
    "import nlp_preprocessing as nlpp\n",
    "importlib.reload(nlpp)\n",
    "#importing our model training module, the reload command is for development\n",
    "import model_training as mdlt\n",
    "importlib.reload(mdlt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The nlp-preprocessing module\n",
    "\n",
    "The module has two classes for now: one deals with the nlp preprocessing of Google News articles, which are talked about in much more depth in another notebook; the other is the analog for GDELT url data.\n",
    "\n",
    "Let's explore these classes and their contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CorpusGoogleNews class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del datagnews\n",
    "datagnews=nlpp.CorpusGoogleNews() # nlpp.CorpusGoogleNews('some/data/directory') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the attributes of the initialized class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagnews.raw_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagnews.datadirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one public method for now: it loads files from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc\n",
      "Apple Inc 1-26-17\n",
      "Apple Inc 1-27-17\n",
      "Apple Inc 1-30-17\n",
      "Apple Inc 1-31-17\n",
      "Apple Inc 2-1-17\n"
     ]
    }
   ],
   "source": [
    "datagnews.data_directory_crawl('AAPL',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which populates datagnews.raw_articles with dataframes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The first day of public trading with President...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>3 Stocks to Watch on Tuesday: Apple Inc. (AAPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The first day of public trading with President...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>3 Stocks to Watch on Tuesday: Apple Inc. (AAPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The smart home market continues to heat up, an...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Alphabet Inc (GOOGL) Steals AI Expert Back Fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reportedly, Apple Inc.’s AAPL management is sc...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Apple (AAPL) Set to Meet Government Officials ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple Inc. (AAPL) executives were in India tod...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Apple Close to Signing Deal With Indian Govern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body   category  \\\n",
       "0  The first day of public trading with President...  Apple Inc   \n",
       "1  The first day of public trading with President...  Apple Inc   \n",
       "2  The smart home market continues to heat up, an...  Apple Inc   \n",
       "3  Reportedly, Apple Inc.’s AAPL management is sc...  Apple Inc   \n",
       "4  Apple Inc. (AAPL) executives were in India tod...  Apple Inc   \n",
       "\n",
       "                                               title  \n",
       "0  3 Stocks to Watch on Tuesday: Apple Inc. (AAPL...  \n",
       "1  3 Stocks to Watch on Tuesday: Apple Inc. (AAPL...  \n",
       "2  Alphabet Inc (GOOGL) Steals AI Expert Back Fro...  \n",
       "3  Apple (AAPL) Set to Meet Government Officials ...  \n",
       "4  Apple Close to Signing Deal With Indian Govern...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagnews.raw_articles['Apple Inc 1-30-17'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CorpusGDELT class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del datagdelt\n",
    "datagdelt=nlpp.CorpusGDELT(min_ment=800) # min_ment defaults to 1 and cuts off events that have a low number of mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the several attributes that the class contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of mentions: 800\n",
      "Current directory: ../data/GDELT_1.0/\n",
      "Dates loaded so far: []\n",
      "Corpus of raw urls []\n",
      "Corpus of tfidf-vectorized docs:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#minimum number of mentions for one event to be used\n",
    "print('Minimum number of mentions:',datagdelt.minimum_ment)\n",
    "print('Current directory:',datagdelt.currentdir) # current directory\n",
    "print('Dates loaded so far:',datagdelt.dates) # dates for which data has been loaded so far\n",
    "print('Corpus of raw urls',datagdelt.url_corpus)\n",
    "print('Corpus of tfidf-vectorized docs:')\n",
    "print(datagdelt.vect_corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vowels: ['a', 'e', 'i', 'o', 'u', 'y']\n",
      "Consonants: ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'z'] \n",
      "Stemmer: <PorterStemmer>\n",
      "Punctuation: re.compile('[-.?!,\":;()|0-9]')\n",
      "Tokenizer: RegexpTokenizer(pattern='\\\\w+', gaps=False, discard_empty=True, flags=56)\n",
      "Filter for spurious url beginnings: re.compile('idind.|idus.|iduk.')\n",
      "Filter for stop words: {'', 'had', 'what', 'these', 'why', 'y', 'over', 'shouldn', 'is', 'himself', 'him', 'won', 'll', 'itself', 'should', 'now', 'herself', 'am', 'too', 'while', 'ourselves', 'here', 'that', 'there', 'some', 'mustn', 'being', 'yourself', 'been', 'by', 'themselves', 'how', 'weren', 'nor', 'each', 'aren', 'between', 'isn', 'yourselves', 'me', 'i', 'once', 'doesn', 'a', 'with', 'your', 'does', 'up', 'or', 'has', 're', 'whom', 'couldn', 'you', 'yours', 'mightn', 'and', 'myself', 'd', 'from', 'more', 'through', 'again', 'if', 'then', 'its', 'other', 'ma', 'for', 'but', 'so', 'hadn', 'do', 'such', 'only', 'when', 'did', 'own', 'o', 'above', 'all', 'be', 'to', 'she', 'of', 'our', 'my', 'further', 's', 'no', 'during', 'wasn', 'as', 'where', 'hers', 'those', 'any', 'same', 'was', 'will', 'have', 'in', 'against', 'after', 'doing', 'very', 'having', 'her', 'both', 'theirs', 'their', 'out', 'shan', 'ain', 'who', 'them', 'didn', 'don', 'wouldn', 've', 'not', 'before', 'they', 'm', 'few', 'can', 'because', 'are', 'until', 'about', 'were', 'into', 'he', 'which', 'off', 'haven', 'this', 'hasn', 'ours', 'just', 'needn', 'it', 'an', 'most', 'we', 'on', 'his', 'under', 'below', 'down', 'than', 't', 'at', 'the'}\n"
     ]
    }
   ],
   "source": [
    "#vowels and consonants\n",
    "print('Vowels:',datagdelt.vowels)\n",
    "print('Consonants:',datagdelt.consonants,end=' ')\n",
    "print()\n",
    "print('Stemmer:',datagdelt.porter) #stemmer of choice\n",
    "print('Punctuation:',datagdelt.punctuation) #punctuation regular expression\n",
    "print('Tokenizer:',datagdelt.re_tokenizer) \n",
    "print('Filter for spurious url beginnings:',datagdelt.spurious_beginnings)\n",
    "print('Filter for stop words:',datagdelt.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GLOBALEVENTID', 'SQLDATE', 'MonthYear', 'Year', 'FractionDate', 'Actor1Code', 'Actor1Name', 'Actor1CountryCode', 'Actor1KnownGroupCode', 'Actor1EthnicCode', 'Actor1Religion1Code', 'Actor1Religion2Code', 'Actor1Type1Code', 'Actor1Type2Code', 'Actor1Type3Code', 'Actor2Code', 'Actor2Name', 'Actor2CountryCode', 'Actor2KnownGroupCode', 'Actor2EthnicCode', 'Actor2Religion1Code', 'Actor2Religion2Code', 'Actor2Type1Code', 'Actor2Type2Code', 'Actor2Type3Code', 'IsRootEvent', 'EventCode', 'EventBaseCode', 'EventRootCode', 'QuadClass', 'GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles', 'AvgTone', 'Actor1Geo_Type', 'Actor1Geo_FullName', 'Actor1Geo_CountryCode', 'Actor1Geo_ADM1Code', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor1Geo_FeatureID', 'Actor2Geo_Type', 'Actor2Geo_FullName', 'Actor2Geo_CountryCode', 'Actor2Geo_ADM1Code', 'Actor2Geo_Lat', 'Actor2Geo_Long', 'Actor2Geo_FeatureID', 'ActionGeo_Type', 'ActionGeo_FullName', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code', 'ActionGeo_Lat', 'ActionGeo_Long', 'ActionGeo_FeatureID', 'DATEADDED', 'SOURCEURL'] "
     ]
    }
   ],
   "source": [
    "print(datagdelt.header,end=' ') #GDELT csv files header, notice the last field has the urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what methods are available and what the pipeline is like.\n",
    "\n",
    "First we load the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done!"
     ]
    }
   ],
   "source": [
    "datagdelt.load_urls('20161001','20170217') #the earliest available date is April 1st 2013 = 20130401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what the url_corpus attribute looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 140 elements in it, because we loaded 140 days!\n",
      "The loaded day n. 5 had 308 events in it that were mentioned more than 800 times:\n",
      " [[1972, 'http://www.philippinetimes.com/index.php/sid/248243461'], [1115, 'http://www.capradio.org/news/npr/story?storyid=496552413'], [970, 'http://thecabin.net/news/2016-10-04/dazzle-daze-raffle-tickets-sale'], [1951, 'http://www.whio.com/news/national-govt--politics/clinton-reaches-out-women-while-trump-defends-taxes/xnmN5QugmLzeGkEBR64y9I/'], [1965, 'http://wgno.com/2016/10/04/this-robot-is-so-realistic-that-it-helps-train-first-responders/'], [1012, 'https://www.stgeorgeutah.com/news/archive/2016/10/04/bureau-of-indian-affairs-discussion-kicks-off-free-brown-bag-lecture-series-full-schedule/'], [925, 'https://www.stgeorgeutah.com/news/archive/2016/10/04/yesco-co-owner-featured-on-undercover-boss-speaks-at-chamber-luncheon/'], [1544, 'http://www.nbcnews.com/politics/2016-election/lid-live-blogging-vice-presidential-debate-n659606?cid=public-rss_20161004'], [1400, 'http://www.floridatoday.com/story/money/2016/10/04/murray-gives-state-port-canaveral-address/91529110/'], [1161, 'http://nbc4i.com/2016/10/04/gop-declares-mike-pence-clear-winner-of-vp-debate-before-it-started/']] \n",
      " etc...\n",
      "The first event was mentioned 1972 times, the second 1115 times, etc...\n"
     ]
    }
   ],
   "source": [
    "day=5 #select one day\n",
    "print('There are',len(datagdelt.url_corpus),'elements in it, because we loaded',len(datagdelt.dates),'days!')\n",
    "print('The loaded day n.',day,'had',len(datagdelt.url_corpus[day-1]) ,'events in it that were mentioned more than',datagdelt.minimum_ment,'times:\\n', datagdelt.url_corpus[day-1][:10],'\\n etc...')\n",
    "print('The first event was mentioned',datagdelt.url_corpus[day-1][0][0],'times, the second',datagdelt.url_corpus[day-1][1][0],'times, etc...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that many of those urls contain wordings that can be very informative on what's happening in the world and therefore might tell us something about the near future of the markets!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's process these messy raw urls! Let's use word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using word2vec vectorization procedure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-19 11:44:04,442 : INFO : collecting all words and their counts\n",
      "2017-02-19 11:44:04,443 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-19 11:44:04,490 : INFO : collected 15000 word types from a corpus of 236610 raw words and 140 sentences\n",
      "2017-02-19 11:44:04,490 : INFO : Loading a fresh vocabulary\n",
      "2017-02-19 11:44:04,549 : INFO : min_count=1 retains 15000 unique words (100% of original 15000, drops 0)\n",
      "2017-02-19 11:44:04,550 : INFO : min_count=1 leaves 236610 word corpus (100% of original 236610, drops 0)\n",
      "2017-02-19 11:44:04,624 : INFO : deleting the raw counts dictionary of 15000 items\n",
      "2017-02-19 11:44:04,625 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2017-02-19 11:44:04,626 : INFO : downsampling leaves estimated 223514 word corpus (94.5% of prior 236610)\n",
      "2017-02-19 11:44:04,626 : INFO : estimated required memory for 15000 words and 48 dimensions: 13260000 bytes\n",
      "2017-02-19 11:44:04,683 : INFO : resetting layer weights\n",
      "2017-02-19 11:44:04,959 : INFO : training model with 3 workers on 15000 vocabulary and 48 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-19 11:44:04,959 : INFO : expecting 140 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-19 11:44:05,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-19 11:44:05,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-19 11:44:05,703 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-19 11:44:05,704 : INFO : training on 1183050 raw words (1117428 effective words) took 0.7s, 1504632 effective words/s\n"
     ]
    }
   ],
   "source": [
    "datagdelt.gdelt_preprocess(vectrz='word2vec',size_w2v=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_1</th>\n",
       "      <th>w2v_10</th>\n",
       "      <th>w2v_11</th>\n",
       "      <th>w2v_12</th>\n",
       "      <th>w2v_13</th>\n",
       "      <th>w2v_14</th>\n",
       "      <th>w2v_15</th>\n",
       "      <th>w2v_16</th>\n",
       "      <th>w2v_17</th>\n",
       "      <th>w2v_18</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_22</th>\n",
       "      <th>w2v_23</th>\n",
       "      <th>w2v_24</th>\n",
       "      <th>w2v_3</th>\n",
       "      <th>w2v_4</th>\n",
       "      <th>w2v_5</th>\n",
       "      <th>w2v_6</th>\n",
       "      <th>w2v_7</th>\n",
       "      <th>w2v_8</th>\n",
       "      <th>w2v_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20161001</th>\n",
       "      <td>-0.135579</td>\n",
       "      <td>0.145710</td>\n",
       "      <td>0.150963</td>\n",
       "      <td>-0.049898</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>-0.080067</td>\n",
       "      <td>0.182112</td>\n",
       "      <td>-0.014674</td>\n",
       "      <td>0.103979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149336</td>\n",
       "      <td>-0.005600</td>\n",
       "      <td>-0.009186</td>\n",
       "      <td>-0.658091</td>\n",
       "      <td>-0.154392</td>\n",
       "      <td>0.203319</td>\n",
       "      <td>-0.223801</td>\n",
       "      <td>0.156598</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>-0.062948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161002</th>\n",
       "      <td>-0.148192</td>\n",
       "      <td>0.134067</td>\n",
       "      <td>0.146997</td>\n",
       "      <td>-0.033446</td>\n",
       "      <td>-0.036487</td>\n",
       "      <td>0.176244</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>-0.034782</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136275</td>\n",
       "      <td>0.018574</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>-0.664830</td>\n",
       "      <td>-0.173978</td>\n",
       "      <td>0.204555</td>\n",
       "      <td>-0.228685</td>\n",
       "      <td>0.137403</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>-0.063401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161003</th>\n",
       "      <td>-0.142121</td>\n",
       "      <td>0.134035</td>\n",
       "      <td>0.158810</td>\n",
       "      <td>-0.025740</td>\n",
       "      <td>-0.035427</td>\n",
       "      <td>0.163111</td>\n",
       "      <td>-0.074129</td>\n",
       "      <td>0.171442</td>\n",
       "      <td>-0.037753</td>\n",
       "      <td>0.115952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144167</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>-0.012171</td>\n",
       "      <td>-0.658845</td>\n",
       "      <td>-0.168502</td>\n",
       "      <td>0.203247</td>\n",
       "      <td>-0.222505</td>\n",
       "      <td>0.138550</td>\n",
       "      <td>0.043704</td>\n",
       "      <td>-0.053548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161004</th>\n",
       "      <td>-0.149176</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>-0.014482</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>0.165278</td>\n",
       "      <td>-0.072817</td>\n",
       "      <td>0.160967</td>\n",
       "      <td>-0.033454</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134668</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>-0.669298</td>\n",
       "      <td>-0.182983</td>\n",
       "      <td>0.205226</td>\n",
       "      <td>-0.228417</td>\n",
       "      <td>0.143929</td>\n",
       "      <td>0.035397</td>\n",
       "      <td>-0.062658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161005</th>\n",
       "      <td>-0.140583</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>0.160435</td>\n",
       "      <td>-0.018698</td>\n",
       "      <td>-0.019044</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>-0.060016</td>\n",
       "      <td>0.171353</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>0.098221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146103</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.669843</td>\n",
       "      <td>-0.169948</td>\n",
       "      <td>0.201957</td>\n",
       "      <td>-0.216390</td>\n",
       "      <td>0.170279</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>-0.069058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161006</th>\n",
       "      <td>-0.143939</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>0.136822</td>\n",
       "      <td>-0.051011</td>\n",
       "      <td>-0.058690</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>-0.096930</td>\n",
       "      <td>0.162577</td>\n",
       "      <td>-0.034926</td>\n",
       "      <td>0.095348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130045</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>-0.654903</td>\n",
       "      <td>-0.166612</td>\n",
       "      <td>0.202456</td>\n",
       "      <td>-0.244021</td>\n",
       "      <td>0.125311</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>-0.059137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161007</th>\n",
       "      <td>-0.140061</td>\n",
       "      <td>0.133492</td>\n",
       "      <td>0.153134</td>\n",
       "      <td>-0.027963</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>0.158093</td>\n",
       "      <td>-0.074293</td>\n",
       "      <td>0.160450</td>\n",
       "      <td>-0.023274</td>\n",
       "      <td>0.096862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133177</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.667467</td>\n",
       "      <td>-0.170896</td>\n",
       "      <td>0.203211</td>\n",
       "      <td>-0.230707</td>\n",
       "      <td>0.149247</td>\n",
       "      <td>0.034228</td>\n",
       "      <td>-0.064662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161008</th>\n",
       "      <td>-0.170171</td>\n",
       "      <td>0.115314</td>\n",
       "      <td>0.114239</td>\n",
       "      <td>-0.023972</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>0.212334</td>\n",
       "      <td>-0.092182</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>-0.048958</td>\n",
       "      <td>0.046495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135059</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.066802</td>\n",
       "      <td>-0.661742</td>\n",
       "      <td>-0.210109</td>\n",
       "      <td>0.196828</td>\n",
       "      <td>-0.250369</td>\n",
       "      <td>0.123787</td>\n",
       "      <td>0.018437</td>\n",
       "      <td>-0.057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161009</th>\n",
       "      <td>-0.123227</td>\n",
       "      <td>0.151773</td>\n",
       "      <td>0.181047</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>-0.052562</td>\n",
       "      <td>0.130993</td>\n",
       "      <td>-0.067063</td>\n",
       "      <td>0.188574</td>\n",
       "      <td>-0.026700</td>\n",
       "      <td>0.141019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>-0.025875</td>\n",
       "      <td>-0.046736</td>\n",
       "      <td>-0.645434</td>\n",
       "      <td>-0.139736</td>\n",
       "      <td>0.201139</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>0.150015</td>\n",
       "      <td>0.051672</td>\n",
       "      <td>-0.047011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161010</th>\n",
       "      <td>-0.175676</td>\n",
       "      <td>0.100656</td>\n",
       "      <td>0.104136</td>\n",
       "      <td>-0.013532</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0.228106</td>\n",
       "      <td>-0.094560</td>\n",
       "      <td>0.140867</td>\n",
       "      <td>-0.056298</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134139</td>\n",
       "      <td>0.058744</td>\n",
       "      <td>0.091294</td>\n",
       "      <td>-0.664773</td>\n",
       "      <td>-0.232322</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>-0.253318</td>\n",
       "      <td>0.120793</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>-0.060490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              w2v_1    w2v_10    w2v_11    w2v_12    w2v_13    w2v_14  \\\n",
       "news_date                                                               \n",
       "20161001  -0.135579  0.145710  0.150963 -0.049898 -0.034872  0.151127   \n",
       "20161002  -0.148192  0.134067  0.146997 -0.033446 -0.036487  0.176244   \n",
       "20161003  -0.142121  0.134035  0.158810 -0.025740 -0.035427  0.163111   \n",
       "20161004  -0.149176  0.124418  0.149711 -0.014482 -0.023597  0.165278   \n",
       "20161005  -0.140583  0.132568  0.160435 -0.018698 -0.019044  0.137025   \n",
       "20161006  -0.143939  0.141425  0.136822 -0.051011 -0.058690  0.188056   \n",
       "20161007  -0.140061  0.133492  0.153134 -0.027963 -0.037490  0.158093   \n",
       "20161008  -0.170171  0.115314  0.114239 -0.023972 -0.002520  0.212334   \n",
       "20161009  -0.123227  0.151773  0.181047 -0.044145 -0.052562  0.130993   \n",
       "20161010  -0.175676  0.100656  0.104136 -0.013532  0.023032  0.228106   \n",
       "\n",
       "             w2v_15    w2v_16    w2v_17    w2v_18    ...       w2v_22  \\\n",
       "news_date                                            ...                \n",
       "20161001  -0.080067  0.182112 -0.014674  0.103979    ...     0.149336   \n",
       "20161002  -0.082453  0.166917 -0.034782  0.094391    ...     0.136275   \n",
       "20161003  -0.074129  0.171442 -0.037753  0.115952    ...     0.144167   \n",
       "20161004  -0.072817  0.160967 -0.033454  0.093653    ...     0.134668   \n",
       "20161005  -0.060016  0.171353 -0.013063  0.098221    ...     0.146103   \n",
       "20161006  -0.096930  0.162577 -0.034926  0.095348    ...     0.130045   \n",
       "20161007  -0.074293  0.160450 -0.023274  0.096862    ...     0.133177   \n",
       "20161008  -0.092182  0.153200 -0.048958  0.046495    ...     0.135059   \n",
       "20161009  -0.067063  0.188574 -0.026700  0.141019    ...     0.156417   \n",
       "20161010  -0.094560  0.140867 -0.056298  0.018654    ...     0.134139   \n",
       "\n",
       "             w2v_23    w2v_24     w2v_3     w2v_4     w2v_5     w2v_6  \\\n",
       "news_date                                                               \n",
       "20161001  -0.005600 -0.009186 -0.658091 -0.154392  0.203319 -0.223801   \n",
       "20161002   0.018574  0.011110 -0.664830 -0.173978  0.204555 -0.228685   \n",
       "20161003   0.006728 -0.012171 -0.658845 -0.168502  0.203247 -0.222505   \n",
       "20161004   0.024593  0.003607 -0.669298 -0.182983  0.205226 -0.228417   \n",
       "20161005   0.013903 -0.018853 -0.669843 -0.169948  0.201957 -0.216390   \n",
       "20161006   0.020371  0.021070 -0.654903 -0.166612  0.202456 -0.244021   \n",
       "20161007   0.021111 -0.002762 -0.667467 -0.170896  0.203211 -0.230707   \n",
       "20161008   0.036627  0.066802 -0.661742 -0.210109  0.196828 -0.250369   \n",
       "20161009  -0.025875 -0.046736 -0.645434 -0.139736  0.201139 -0.209978   \n",
       "20161010   0.058744  0.091294 -0.664773 -0.232322  0.190728 -0.253318   \n",
       "\n",
       "              w2v_7     w2v_8     w2v_9  \n",
       "news_date                                \n",
       "20161001   0.156598  0.026930 -0.062948  \n",
       "20161002   0.137403  0.024689 -0.063401  \n",
       "20161003   0.138550  0.043704 -0.053548  \n",
       "20161004   0.143929  0.035397 -0.062658  \n",
       "20161005   0.170279  0.031264 -0.069058  \n",
       "20161006   0.125311  0.029238 -0.059137  \n",
       "20161007   0.149247  0.034228 -0.064662  \n",
       "20161008   0.123787  0.018437 -0.057738  \n",
       "20161009   0.150015  0.051672 -0.047011  \n",
       "20161010   0.120793  0.005628 -0.060490  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagdelt.word2vec_corpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOM! Now we have all of our datapoints with their nlp features neatly arranged in a pandas dataframe, ready for processing. Mission accomplished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to run this expensive preprocessing again on the same exact data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using word2vec vectorization procedure\n",
      "Nothing to be done, dataframes are up to date\n"
     ]
    }
   ],
   "source": [
    "datagdelt.gdelt_preprocess(vectrz='word2vec',size_w2v=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay for savings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the model training class, feeding it the dataframe from the nlp processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The model training module (work in progress, please be patient)\n",
    "This section covers model training, validation, and testing, from our model_training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model_training as mdlt\n",
    "importlib.reload(mdlt)\n",
    "tet=mdlt.StockPrediction([['word2vec'],[datagdelt.word2vec_corpus],[datagdelt.w2vec_model]],update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an L1 linear regressor which is trying to predict the increase/decrease of tomorrow's S&P index over today's. We test on the last 20 days out of 50 and validate/tune, for every testing case, over the previous 10 days. As for the hyperparameters, we are letting our regularization parameter be searched for in the 0.001-3000 range and we allow for 40 iterations of the optimal parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3k/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 15.351 benchmark_test_rmse: 15.351\n",
      "model_test_rmse: 3.403 benchmark_test_rmse: 3.403\n",
      "model_test_rmse: 0.653 benchmark_test_rmse: 0.653\n",
      "model_test_rmse: 0.025 benchmark_test_rmse: 0.025\n",
      "model_test_rmse: 15.245 benchmark_test_rmse: 15.245\n",
      "model_test_rmse: 6.362 benchmark_test_rmse: 6.362\n",
      "model_test_rmse: 0.909 benchmark_test_rmse: 0.909\n",
      "model_test_rmse: 0.172 benchmark_test_rmse: 0.172\n",
      "model_test_rmse: 11.780 benchmark_test_rmse: 11.780\n",
      "model_test_rmse: 6.679 benchmark_test_rmse: 6.679\n",
      "model_test_rmse: 10.525 benchmark_test_rmse: 10.525\n",
      "model_test_rmse: 7.591 benchmark_test_rmse: 7.591\n",
      "model_test_rmse: 9.849 benchmark_test_rmse: 9.849\n",
      "model_test_rmse: 3.955 benchmark_test_rmse: 3.955\n",
      "model_test_rmse: 2.056 benchmark_test_rmse: 2.056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(6.3036606676414557, 5.1252792112508061),\n",
       " (6.3036606676414557, 5.1252792112508061)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','lasso',[['alpha',[0.001,7000.,60.]]],parm_search_iter=40,n_folds_val=15,\n",
    "                         past_depth=60,n_folds_test=15,scaling=True,differential=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is not particularly promising. How about we try a random forest regressor instead? We are letting our tuning select any combination among 5 values for the number of estimators, 5 for the maximum number of features used for splitting, and we allow a maximum depth from 5 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 6.430 benchmark_test_rmse: 7.466\n"
     ]
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','rfreg',[['n_estim',{5,6,7}],['max_feat',{26,27,35,37,40,45,48}],\n",
    "                                             ['max_depth',{4,5,6,7,8,9}]],parm_search_iter=1,n_folds_val=15,\n",
    "                         past_depth=20,n_folds_test=20,scaling=True,differential=True,verbose=False,notest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.00350041])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp=tet.models['word2vec'].coef_#.feature_importances_\n",
    "feat_imp\n",
    "#these are the feature importances for a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=tet.w2v_models['word2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('list', 0.9997903108596802),\n",
       " ('pay', 0.9997895956039429),\n",
       " ('media', 0.9997743368148804),\n",
       " ('american', 0.9997565746307373),\n",
       " ('job', 0.9997377991676331),\n",
       " ('governor', 0.9997320175170898),\n",
       " ('war', 0.9997308254241943),\n",
       " ('deal', 0.9997145533561707),\n",
       " ('lawmak', 0.9997134208679199),\n",
       " ('week', 0.9997121095657349)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('irctc', 0.8196725845336914),\n",
       " ('underdog', 0.8064718246459961),\n",
       " ('bernhard', 0.8056542873382568),\n",
       " ('trailguid', 0.7977608442306519),\n",
       " ('cadeb', 0.7947107553482056),\n",
       " ('bigli', 0.7910323739051819),\n",
       " ('mulhal', 0.7737561464309692),\n",
       " ('dickinson', 0.7713722586631775),\n",
       " ('restless', 0.768715500831604),\n",
       " ('marque', 0.7666662931442261)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=23\n",
    "aa=np.zeros(24)\n",
    "aa[0]=feat_imp[0]\n",
    "aa[1]=feat_imp[1]\n",
    "aa[2]=-feat_imp[2]\n",
    "aa[3]=feat_imp[3]\n",
    "aa[4]=-feat_imp[4]\n",
    "aa[5]=feat_imp[5]\n",
    "aa[6]=-feat_imp[6]\n",
    "aa[7]=feat_imp[7]\n",
    "aa[8]=feat_imp[8]\n",
    "aa[9]=-feat_imp[9]\n",
    "aa[10]=-feat_imp[10]\n",
    "aa[11]=-feat_imp[11]\n",
    "aa[12]=feat_imp[12]\n",
    "aa[13]=-feat_imp[13]\n",
    "aa[14]=feat_imp[14]\n",
    "aa[15]=feat_imp[15]\n",
    "aa[16]=feat_imp[16]\n",
    "aa[17]=feat_imp[17]\n",
    "aa[18]=-feat_imp[18]\n",
    "aa[19]=-feat_imp[19]\n",
    "aa[20]=-feat_imp[20]\n",
    "aa[21]=-feat_imp[21]\n",
    "aa[22]=-feat_imp[22]\n",
    "aa[n]=-feat_imp[n]\n",
    "model.wv.similar_by_vector(aa)#,model.wv.similar_by_vector(-aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 4.89339233333 flat_test_rmse: 8.60856807692\n",
      "model_test_rmse: 8.960082 flat_test_rmse: 12.9865546429\n",
      "model_test_rmse: 16.7501225 flat_test_rmse: 15.5507163333\n",
      "model_test_rmse: 3.189942 flat_test_rmse: 5.4114374375\n",
      "model_test_rmse: 12.386638 flat_test_rmse: 5.39292358824\n",
      "model_test_rmse: 15.8485800714 flat_test_rmse: 16.8933647222\n",
      "model_test_rmse: 0.0397940000003 flat_test_rmse: 4.24398626316\n",
      "model_test_rmse: 7.4552 flat_test_rmse: 1.32206995\n",
      "model_test_rmse: 3.16670766667 flat_test_rmse: 0.638997238095\n",
      "model_test_rmse: 8.20413614286 flat_test_rmse: 14.6598230909\n",
      "model_test_rmse: 5.20131128571 flat_test_rmse: 7.40724752174\n",
      "model_test_rmse: 3.630006 flat_test_rmse: 1.71873020833\n",
      "model_test_rmse: 6.07581386667 flat_test_rmse: 0.580156\n",
      "model_test_rmse: 9.91398693571 flat_test_rmse: 11.0525086923\n",
      "model_test_rmse: 7.266972 flat_test_rmse: 5.67294251852\n",
      "model_test_rmse: 2.48998975 flat_test_rmse: 9.39025842857\n",
      "model_test_rmse: 3.64998333333 flat_test_rmse: 6.24663241379\n",
      "model_test_rmse: 4.6734129 flat_test_rmse: 8.37825533333\n",
      "model_test_rmse: 13.819946 flat_test_rmse: 5.59196196774\n",
      "model_test_rmse: 2.4220709 flat_test_rmse: 0.55275684375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7.0019043842857176, 4.5739688827417986),\n",
       " (7.1149945635660883, 4.9619411960085946)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','rfreg',[['n_estim',{1,2,3,5,7}],['max_feat',{21,22,23,24}],['max_depth',{5,6,7}]],\n",
    "                         parm_search_iter=1,n_folds_val=6,n_folds_test=20,scaling=True,differential=True,verbose=False,\n",
    "                         notest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model does sometimes on average perform better than the benchmark one (root mean squared error of 7.0 vs 7.1 in this specific case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to get a prediction for today, we toggle the 'notest' attribute to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't predict for tomorrow, because the stock market is closed\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-3eb229edd25c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tet.auto_ts_val_test_reg('word2vec','rfreg',[['n_estim',{1,2,3,5,7}],['max_feat',{21,22,23,24}],['max_depth',{5,6,7}]],\n\u001b[1;32m      2\u001b[0m                          \u001b[0mparm_search_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdifferential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                          notest=True)\n\u001b[0m",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36mauto_ts_val_test_reg\u001b[0;34m(self, dataset_id, regressor, parm_ranges, parm_search_iter, n_folds_val, n_folds_test, scaling, differential, one_shot, verbose, notest, seed)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnotest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoday_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoday_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, dataset_id, today_pred)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoday_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodaysx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_x_today\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36m_prepare_x_today\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_tomorrow_we\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I can't predict for tomorrow, because the stock market is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_tomorrow_mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mafter_weekend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','rfreg',[['n_estim',{1,2,3,5,7}],['max_feat',{21,22,23,24}],['max_depth',{5,6,7}]],\n",
    "                         parm_search_iter=1,n_folds_val=6,n_folds_test=20,scaling=True,differential=True,verbose=False,\n",
    "                         notest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 3.019775 flat_test_rmse: 7.40724752174\n",
      "model_test_rmse: 8.410034 flat_test_rmse: 1.71873020833\n",
      "model_test_rmse: 6.6198125 flat_test_rmse: 0.580156\n",
      "model_test_rmse: 17.930257 flat_test_rmse: 11.0525086923\n",
      "model_test_rmse: 11.505005 flat_test_rmse: 5.67294251852\n",
      "model_test_rmse: 8.880004 flat_test_rmse: 9.39025842857\n",
      "model_test_rmse: 3.10017866667 flat_test_rmse: 6.24663241379\n",
      "model_test_rmse: 0.929932 flat_test_rmse: 8.37825533333\n",
      "model_test_rmse: 12.530029 flat_test_rmse: 5.59196196774\n",
      "model_test_rmse: 3.84002725 flat_test_rmse: 0.55275684375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7.6765054416666727, 4.993188530339169),\n",
       " (5.6591449928088533, 3.4814802333665931)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','knnreg',[['numb_nn',{1,2,3,4}]],parm_search_iter=4,n_folds_val=6,n_folds_test=10,\n",
    "                         scaling=True,differential=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't predict for tomorrow, because the stock market is closed\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-50ff8f1f7229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tet.auto_ts_val_test_reg('word2vec','knnreg',[['numb_nn',{1,2,3,4}]],parm_search_iter=4,n_folds_val=6,n_folds_test=10,\n\u001b[0;32m----> 2\u001b[0;31m                          scaling=True,differential=True,notest=True,verbose=False)\n\u001b[0m",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36mauto_ts_val_test_reg\u001b[0;34m(self, dataset_id, regressor, parm_ranges, parm_search_iter, n_folds_val, n_folds_test, scaling, differential, one_shot, verbose, notest, seed)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnotest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoday_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoday_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, dataset_id, today_pred)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoday_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodaysx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_x_today\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/notebooks/../source/model_training.py\u001b[0m in \u001b[0;36m_prepare_x_today\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_tomorrow_we\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I can't predict for tomorrow, because the stock market is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_tomorrow_mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mafter_weekend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','knnreg',[['numb_nn',{1,2,3,4}]],parm_search_iter=4,n_folds_val=6,n_folds_test=10,\n",
    "                         scaling=True,differential=True,notest=True,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([[ 0.2,  1. ,  0.2]]), array([[ 0.4,  0. ,  0.4]])),\n",
       " (array([[ 0.8,  0.9,  0.7]]),\n",
       "  array([[ 0.4       ,  0.3       ,  0.45825757]]))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','logreg',[['l1orl2?',{'l1',}],\n",
    "                                                ['C',[0.0000000000001,0.001,0.000001]]],\n",
    "                           parm_search_iter=30,n_folds_val=10,n_folds_test=10,past_depth=15,scaling=False,notest=False,\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([[ 0.5,  0.9,  0.4]]),\n",
       "  array([[ 0.5       ,  0.3       ,  0.48989795]])),\n",
       " (array([[ 0.65,  0.9 ,  0.55]]),\n",
       "  array([[ 0.4769696 ,  0.3       ,  0.49749372]]))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','rfclass',[['n_estim',{1,2,3,4,5,6,7}],['max_feat',{8,10,12,14,18,22,23,24}],\n",
    "                                                 ['max_depth',{4,5,6}]],parm_search_iter=1,n_folds_val=10,past_depth=15,\n",
    "                           n_folds_test=20,scaling=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([[ 0.9,  0.8,  0.7]]),\n",
       "  array([[ 0.3       ,  0.4       ,  0.45825757]])),\n",
       " (array([[ 0.75,  0.75,  0.5 ]]),\n",
       "  array([[ 0.4330127,  0.4330127,  0.5      ]]))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','rfclass',[['n_estim',{1,2,3,4,5,6,7}],['max_feat',{8,10,12,14,18,22,23,24}],\n",
    "                                                 ['max_depth',{4,5,6}]],parm_search_iter=1,n_folds_val=10,\n",
    "                           n_folds_test=20,scaling=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Our model consistently overperform the benchmark as for accuracy (=F1 in this case): 0.7 vs 0.5.\n",
    "\n",
    "Now let's predict what today's closing is going to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','rfclass',[['n_estim',{1,2,3,4,5,6,7}],['max_feat',{8,12}],['max_depth',{4,6}]],\n",
    "                           parm_search_iter=1,n_folds_val=10,n_folds_test=25,scaling=False,one_shot=True,notest=True,\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-bc8831b4fd77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_imp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeat_imp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#remember: only the first n-2 features are nlp, the (n-1)-th is being after a weekend and the n-th is today's closing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "feat_imp=tet.models['word2vec'].coef_\n",
    "feat_imp\n",
    "#remember: only the first n-2 features are nlp, the (n-1)-th is being after a weekend and the n-th is today's closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will go up, apparently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [0.0, 1.0, 0.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 1.0, 1.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n",
      "test_rec,prec,F1: [1.0, 0.0, 0.0] benchmark_rec,prec,F1: [1.0, 0.0, 0.0]\n",
      "test_rec,prec,F1: [0.0, 1.0, 0.0] benchmark_rec,prec,F1: [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([[ 0.6,  0.9,  0.5]]),\n",
       "  array([[ 0.48989795,  0.3       ,  0.5       ]])),\n",
       " (array([[ 0.9,  0.8,  0.7]]),\n",
       "  array([[ 0.3       ,  0.4       ,  0.45825757]]))]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','knnclass',[['n_neighb',{1,2,3,4}]],parm_search_iter=1,\n",
    "                           n_folds_val=6,n_folds_test=10,scaling=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tet.auto_ts_val_test_class('word2vec','svmclass',[['C',[0.000001,1.,0.001]],['kernel',{'poly',}]],\n",
    "                           parm_search_iter=15,n_folds_val=10,n_folds_test=15,scaling=True,notest=False,\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1843.12623653])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.yhat_reg['word2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mercenari', 0.5851517915725708),\n",
       " ('albuquerqu', 0.5756868124008179),\n",
       " ('camper', 0.4917409121990204),\n",
       " ('honeywel', 0.48540031909942627),\n",
       " ('consequenti', 0.4711318612098694),\n",
       " ('surinam', 0.4206582307815552),\n",
       " ('yankton', 0.41216057538986206),\n",
       " ('kat', 0.40529105067253113),\n",
       " ('lyme', 0.40325677394866943),\n",
       " ('mornington', 0.390191912651062)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=np.zeros(32)\n",
    "aa[30]=1\n",
    "model.wv.similar_by_vector(res[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1828.459961])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.ydata['word2vec'][1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 12.0795343059 avg_validation_rmse: 11.9635335428\n"
     ]
    }
   ],
   "source": [
    "tet.kfold_val_reg(10,'word2vec','svmreg',[0.000000000000000000001,'poly'],100,scaling=False,differential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3k/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 2.63499875554 flat_test_rmse: 8.60856807692\n",
      "model_test_rmse: 9.14430435726 flat_test_rmse: 12.9865546429\n",
      "model_test_rmse: 23.9881516511 flat_test_rmse: 15.5507163333\n",
      "model_test_rmse: 11.4025187908 flat_test_rmse: 5.4114374375\n",
      "model_test_rmse: 5.21515508858 flat_test_rmse: 5.39292358824\n",
      "model_test_rmse: 2.66571579527 flat_test_rmse: 16.8933647222\n",
      "model_test_rmse: 2.77283964558 flat_test_rmse: 4.24398626316\n",
      "model_test_rmse: 1.13300009011 flat_test_rmse: 1.32206995\n",
      "model_test_rmse: 0.0744177398856 flat_test_rmse: 0.638997238095\n",
      "model_test_rmse: 15.9667312097 flat_test_rmse: 14.6598230909\n",
      "model_test_rmse: 8.5881427328 flat_test_rmse: 7.40724752174\n",
      "model_test_rmse: 2.84202594862 flat_test_rmse: 1.71873020833\n",
      "model_test_rmse: 3.95979868099 flat_test_rmse: 0.580156\n",
      "model_test_rmse: 15.7528918614 flat_test_rmse: 11.0525086923\n",
      "model_test_rmse: 13.0841439217 flat_test_rmse: 5.67294251852\n",
      "model_test_rmse: 23.4026069352 flat_test_rmse: 9.39025842857\n",
      "model_test_rmse: 7.63390407267 flat_test_rmse: 6.24663241379\n",
      "model_test_rmse: 8.15878505347 flat_test_rmse: 8.37825533333\n",
      "model_test_rmse: 8.4135780817 flat_test_rmse: 5.59196196774\n",
      "model_test_rmse: 0.244825501661 flat_test_rmse: 0.55275684375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(8.3539267956979426, 6.9235143583625938),\n",
       " (7.1149945635660883, 4.9619411960085946)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet.auto_ts_val_test_reg('word2vec','ridge',[['alpha',[0.5,5000.,6.]]],parm_search_iter=30,n_folds_val=10,\n",
    "                         n_folds_test=20,scaling=True,differential=True,notest=False,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a class instance by loading into it two lists: one of names of your choosing and one of dataframes, which in this case is the output form the previous module above, datagdelt.vect_corpus_tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some_name_you_choose']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, for the real deal: k-fold training and validation!\n",
    "The following method performs that in a very general manner. It lets you decide what regression model to choose, as well as the values of the hyperparameters (please see the module documentation in model_training.py for details on how to pass the hyperparameters), also you need to supply the number of folds you want your data split into, and a seed, for reproducibility. There is also an option to scale and normalize the features but it doesn't quite perform well in general.\n",
    "\n",
    "The method returns the model average performance over the k training iterations. In short, tuning will consist of choosing the value for the hyperparameters that optimizes avg_validation_rmse (that is minimize the average root mean squared on the validation datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 11.2\n",
      "avg_train_rmse: 11.6470100241 avg_validation_rmse: 11.8295047334\n",
      "alpha = 11.3\n",
      "avg_train_rmse: 11.6470935177 avg_validation_rmse: 11.8295020586\n",
      "alpha = 11.4\n",
      "avg_train_rmse: 11.6471777528 avg_validation_rmse: 11.8295001005\n",
      "alpha = 11.5\n",
      "avg_train_rmse: 11.6472627295 avg_validation_rmse: 11.8294988592\n",
      "alpha = 11.6\n",
      "avg_train_rmse: 11.6473484476 avg_validation_rmse: 11.8294983351\n",
      "alpha = 11.7\n",
      "avg_train_rmse: 11.6474349073 avg_validation_rmse: 11.8294985283\n",
      "alpha = 11.8\n",
      "avg_train_rmse: 11.6475221085 avg_validation_rmse: 11.829499439\n",
      "alpha = 11.9\n",
      "avg_train_rmse: 11.6476100511 avg_validation_rmse: 11.8295010676\n",
      "alpha = 12.0\n",
      "avg_train_rmse: 11.6476987351 avg_validation_rmse: 11.8295034142\n",
      "alpha = 12.1\n",
      "avg_train_rmse: 11.6477881607 avg_validation_rmse: 11.8295064791\n",
      "alpha = 12.2\n",
      "avg_train_rmse: 11.6478783276 avg_validation_rmse: 11.8295102625\n",
      "alpha = 12.3\n",
      "avg_train_rmse: 11.6479692359 avg_validation_rmse: 11.8295147646\n",
      "alpha = 12.4\n",
      "avg_train_rmse: 11.6480608856 avg_validation_rmse: 11.8295199856\n",
      "alpha = 12.5\n",
      "avg_train_rmse: 11.6481532766 avg_validation_rmse: 11.8295259259\n",
      "alpha = 12.6\n",
      "avg_train_rmse: 11.648246409 avg_validation_rmse: 11.8295325856\n",
      "alpha = 12.7\n",
      "avg_train_rmse: 11.6483402828 avg_validation_rmse: 11.8295399649\n"
     ]
    }
   ],
   "source": [
    "#10-fold validated lasso linear regression with sliding hyperparameter alpha, seed=100, no scaling, \n",
    "#for dataset 'some_name_you_choose'.\n",
    "for alpha in [12.+0.1*i for i in range(-8,8)]:\n",
    "    print('alpha =',alpha)\n",
    "    predictorgdelt.kfold_val_reg(10,'some_name_you_choose','lasso',alpha,100,scaling=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the minimum is reached for alpha = 11.6 (you'll probably get different values). So now we go into testing and use this parameter.\n",
    "\n",
    "The following method, very similar to the previous one, retrains the model on the full train+validation dataset with the desired hyperparameters. If the model defines feature importances, these are returned by the method.\n",
    "\n",
    "Importantly, the method also prints out the performance of a benchmark model (just a trivial flat prediction from today to tomorrow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By chance, in this one case we outperform the benchmark model with a lower rmse, but this procedure should be performed a couple of time and an average final performance should be quoted instead.\n",
    "\n",
    "Out of curiosity, let's see what the most important features were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which, isn't surprising. As we said at the beginning, the most important feature should have been today's closing, and it was, entirely offuscating everything else.\n",
    "\n",
    "Let's see if classifying tomorrow's value going up or down will do us and better...\n",
    "N.B. We need to specify a decision threshold which I recommend leaving at 0.5 for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the method returns again average validation performances which are now measured in terms of recall, precision, and F1 score. In lack of a specific metric we want to optimize, we are going to use the F1 score for tuning.\n",
    "\n",
    "The performance plateaus and is optimal for alpha ~1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! Our model predicts all 1's. Not much gained...\n",
    "\n",
    "Incidentally anyway, that's how you pull the predictions vector for a specific dataset.\n",
    "In the future I'll give the option to save a specific model run instead of overwriting. Good for free exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch from now on, please ignore!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 9.20135417438 avg_validation_rmse: 23.8508310037\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','lasso',1.3,10,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 5.91587243572 avg_validation_rmse: 24.4121821352\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','rfreg',[50,4500,10],10,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 11.1816716619 avg_validation_rmse: 15.3459786376\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','adabreg',15,10,scaling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 10.342872738 avg_validation_rmse: 11.4892361364\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','knnreg',7,10,scaling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 16.0651087792 flat_test_rmse: 14.4209762157\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_reg('apriltodectfidf','knnreg',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [0.81837529044943147, 0.70479197132136429, 0.75720674859733283] avg_validation_rec,prec,F1: [0.76335497835497834, 0.64537684537684537, 0.6926744610887835]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'apriltodectfidf','knnclass',7,10,[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [0.5, 0.41666666666666669, 0.45454545454545453]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_test_class('apriltodectfidf','knnclass',7,[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [1.0, 0.71820616787952551, 0.83593883914424061] avg_validation_rec,prec,F1: [1.0, 0.59458333333333324, 0.73921100638491943]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'apriltodectfidf','rfclass',[40,5,10],10,[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 0.51282051282051277, 0.67796610169491522]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_test_class('apriltodectfidf','rfclass',[40,5,10],[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51282051282051277"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictorgdelt.ydata['apriltodectfidf'][1][:,1])/len(predictorgdelt.ydata['apriltodectfidf'][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5128205128205128, 0.6779661016949152, 0.5128205128205128)"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlt.scores(predictorgdelt.ydata['apriltodectfidf'][1][:,1],np.ones(len(predictorgdelt.ydata['apriltodectfidf'][1])),[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [1.0, 0.59213718334048937, 0.74374608177131407] avg_validation_rec,prec,F1: [1.0, 0.59458333333333324, 0.73921100638491943]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'apriltodectfidf','logreg',['l1',1.5],10,[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [1.0, 0.51282051282051277, 0.67796610169491522]\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_class('apriltodectfidf','logreg',['l1',2.5],[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [0.76262732475581552, 0.77500920878424662, 0.7669871458718045] avg_validation_rec,prec,F1: [0.66152958152958141, 0.61717171717171726, 0.62368359527432093]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'apriltodectfidf','svmclass',[1.,'poly'],10,[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [0.65000000000000002, 0.59090909090909094, 0.61904761904761907]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_test_class('apriltodectfidf','svmclass',[1.,'poly'],[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apriltodectfidf': array([ 0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
       "         0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "         0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.])}"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.yhat_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.ydata['apriltodectfidf'][1][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-660-12c529f1bcd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictorgdelt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfold_val_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'apriltodectfidf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'svmreg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Maxos/Desktop/Insight_stuff/bigsnippyrepo/maqro/model_training.py\u001b[0m in \u001b[0;36mkfold_val_reg\u001b[0;34m(self, n_folds_val, dataset_id, regressor, parm, seed, differential, scaling)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'houston, we have an unknown model problem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                         \u001b[0mavg_rms_mod_val\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mavg_rms_mod_train\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3k/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3k/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','svmreg',[15,'poly'],10,scaling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 12.6222333907 avg_validation_rmse: 12.1568874732\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','mlpreg',['relu',(100,)],10,scaling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 14.8924855598 flat_test_rmse: 14.4209762157\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_reg('apriltodectfidf','mlpreg',['relu',(100,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apriltodectfidf': array([ 1744.52278741,  1803.29915885,  1694.4451712 ,  1693.34940803,\n",
       "         1837.50763223,  1661.97637678,  1576.88280783,  1647.17413376,\n",
       "         1653.98888935,  1660.05401055,  1630.59372504,  1760.84365842,\n",
       "         1594.12637618,  1693.15485608,  1657.5242832 ,  1559.35083745,\n",
       "         1693.66655617,  1770.69578534,  1678.18873354,  1618.16557548,\n",
       "         1798.57971612,  1595.75929349,  1790.80377837,  1762.44887651,\n",
       "         1569.11649056,  1588.40738375,  1769.48474365,  1773.99257709,\n",
       "         1789.57343515,  1688.86454837,  1637.86982931,  1793.05291322,\n",
       "         1655.27695931,  1687.8802146 ,  1631.17041088,  1657.8406513 ,\n",
       "         1655.79591841,  1562.46506112,  1711.34272805])}"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.yhat_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1754.670044,  1800.900024,  1703.199951,  1689.469971,\n",
       "        1841.069946,  1650.469971,  1553.689941,  1642.810059,\n",
       "        1667.469971,  1630.47998 ,  1612.52002 ,  1767.930054,\n",
       "        1592.430054,  1685.72998 ,  1655.079956,  1541.609985,\n",
       "        1681.550049,  1767.689941,  1655.449951,  1606.280029,\n",
       "        1795.150024,  1573.089966,  1785.030029,  1756.540039,\n",
       "        1570.25    ,  1593.609985,  1747.150024,  1786.540039,\n",
       "        1787.869995,  1689.130005,  1633.77002 ,  1792.810059,\n",
       "        1628.930054,  1706.869995,  1639.040039,  1652.619995,\n",
       "        1642.800049,  1562.5     ,  1698.060059])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.ydata['apriltodectfidf'][1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 6.33518759404 avg_validation_rmse: 24.5460444404\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'apriltodectfidf','ridge',0.001,10,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 14.2964522937 flat_test_rmse: 13.5413782105\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_reg('7daystfidf','lasso',37.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 11.1986058145 avg_validation_rmse: 10.800359651\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(15,'7daystfidf','ridge',8400.,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 14.3814887421 flat_test_rmse: 13.5413782105\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_reg('7daystfidf','ridge',8400.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rmse: 11.0071954777 avg_validation_rmse: 12.3585904621\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_reg(10,'7daystfidf','svreg',[0.01,'poly'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test_rmse: 10.3370215097 flat_test_rmse: 10.8353511909\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_test_reg('7daystfidf','svreg',[0.01,'poly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_cols=list(datagdelt.vect_corpus_tfidf.columns)+['*weekend?','*yesterdayS&P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['north', 2.1730974001773933],\n",
       " ['train', 1.5123459726524862],\n",
       " ['snowden', 1.264379084303753],\n",
       " ['crew', -1.130072887205146],\n",
       " ['big', 1.0974619202530456],\n",
       " ['ae', -0.84521265295771053],\n",
       " ['milit', -0.26812945924067383],\n",
       " ['*yesterdayS&P', 1.8144839374748277e-05],\n",
       " ['juli', 0.0],\n",
       " ['exam', 0.0],\n",
       " ['everi', 0.0],\n",
       " ['everybodi', 0.0],\n",
       " ['evict', 0.0],\n",
       " ['evid', 0.0],\n",
       " ['evolut', 0.0],\n",
       " ['ex', 0.0],\n",
       " ['exactli', 0.0],\n",
       " ['examin', 0.0],\n",
       " ['egyptian', 0.0],\n",
       " ['exce', 0.0],\n",
       " ['except', 0.0],\n",
       " ['exception', 0.0],\n",
       " ['exchang', 0.0],\n",
       " ['exclus', 0.0],\n",
       " ['exec', 0.0],\n",
       " ['execut', 0.0],\n",
       " ['juror', 0.0],\n",
       " ['ever', 0.0],\n",
       " ['eventu', 0.0],\n",
       " ['event', 0.0],\n",
       " ['etern', 0.0],\n",
       " ['ethanol', 0.0],\n",
       " ['ethnic', 0.0],\n",
       " ['etx', 0.0],\n",
       " ['eu', 0.0],\n",
       " ['eurasian', 0.0],\n",
       " ['eurobank', 0.0],\n",
       " ['europ', 0.0],\n",
       " ['european', 0.0],\n",
       " ['eurozon', 0.0],\n",
       " ['evacu', 0.0],\n",
       " ['evad', 0.0],\n",
       " ['evalu', 0.0],\n",
       " ['eve', 0.0],\n",
       " ['even', 0.0],\n",
       " ['exelon', 0.0],\n",
       " ['exercis', 0.0],\n",
       " ['exhaust', 0.0],\n",
       " ['express', 0.0],\n",
       " ['extens', 0.0],\n",
       " ['extra', 0.0],\n",
       " ['extradit', 0.0],\n",
       " ['extrem', 0.0],\n",
       " ['exxon', 0.0],\n",
       " ['eye', 0.0],\n",
       " ['fa', 0.0],\n",
       " ['faa', 0.0],\n",
       " ['faaaa', 0.0],\n",
       " ['faacac', 0.0],\n",
       " ['faacd', 0.0],\n",
       " ['faae', 0.0],\n",
       " ['fabc', 0.0],\n",
       " ['fabulist', 0.0],\n",
       " ['facaedceab', 0.0],\n",
       " ['extend', 0.0],\n",
       " ['export', 0.0],\n",
       " ['exhibit', 0.0],\n",
       " ['explos', 0.0],\n",
       " ['exit', 0.0],\n",
       " ['expand', 0.0],\n",
       " ['expans', 0.0],\n",
       " ['expect', 0.0],\n",
       " ['expeditor', 0.0],\n",
       " ['expel', 0.0],\n",
       " ['expens', 0.0],\n",
       " ['experi', 0.0],\n",
       " ['expert', 0.0],\n",
       " ['expir', 0.0],\n",
       " ['explain', 0.0],\n",
       " ['explan', 0.0],\n",
       " ['explod', 0.0],\n",
       " ['exploit', 0.0],\n",
       " ['explor', 0.0],\n",
       " ['estim', 0.0],\n",
       " ['estat', 0.0],\n",
       " ['establish', 0.0],\n",
       " ['elizabeth', 0.0],\n",
       " ['ellesmer', 0.0],\n",
       " ['elsewher', 0.0],\n",
       " ['elus', 0.0],\n",
       " ['email', 0.0],\n",
       " ['embassi', 0.0],\n",
       " ['embezzl', 0.0],\n",
       " ['embrac', 0.0],\n",
       " ['embroil', 0.0],\n",
       " ['emerg', 0.0],\n",
       " ['emiss', 0.0],\n",
       " ['emit', 0.0],\n",
       " ['emmi', 0.0],\n",
       " ['empir', 0.0],\n",
       " ['employ', 0.0],\n",
       " ['employe', 0.0],\n",
       " ['elkin', 0.0],\n",
       " ['elit', 0.0],\n",
       " ['enclosur', 0.0],\n",
       " ['elig', 0.0],\n",
       " ['eheptgihnqo', 0.0],\n",
       " ['eight', 0.0],\n",
       " ['eject', 0.0],\n",
       " ['el', 0.0],\n",
       " ['elan', 0.0],\n",
       " ['elbaradei', 0.0],\n",
       " ['elderli', 0.0],\n",
       " ['elect', 0.0],\n",
       " ['elector', 0.0],\n",
       " ['electr', 0.0],\n",
       " ['electron', 0.0],\n",
       " ['elementari', 0.0],\n",
       " ['eleph', 0.0],\n",
       " ['elev', 0.0],\n",
       " ['eleven', 0.0],\n",
       " ['en', 0.0],\n",
       " ['encount', 0.0],\n",
       " ['est', 0.0],\n",
       " ['envoy', 0.0],\n",
       " ['eri', 0.0],\n",
       " ['erian', 0.0],\n",
       " ['eric', 0.0],\n",
       " ['errand', 0.0],\n",
       " ['ert', 0.0],\n",
       " ['erupt', 0.0],\n",
       " ['escap', 0.0],\n",
       " ['escape', 0.0],\n",
       " ['escondido', 0.0],\n",
       " ['escort', 0.0],\n",
       " ['eshenbaugh', 0.0],\n",
       " ['eskom', 0.0],\n",
       " ['especi', 0.0],\n",
       " ['espionag', 0.0],\n",
       " ['essam', 0.0],\n",
       " ['epa', 0.0],\n",
       " ['environment', 0.0],\n",
       " ['end', 0.0],\n",
       " ['environ', 0.0],\n",
       " ['endlessli', 0.0],\n",
       " ['endors', 0.0],\n",
       " ['enemi', 0.0],\n",
       " ['energi', 0.0],\n",
       " ['enforc', 0.0],\n",
       " ['engin', 0.0],\n",
       " ['england', 0.0],\n",
       " ['engulf', 0.0],\n",
       " ['enough', 0.0],\n",
       " ['enrich', 0.0],\n",
       " ['enrol', 0.0],\n",
       " ['ensign', 0.0],\n",
       " ['enter', 0.0],\n",
       " ['enthusiast', 0.0],\n",
       " ['entranc', 0.0],\n",
       " ['face', 0.0],\n",
       " ['facebook', 0.0],\n",
       " ['facial', 0.0],\n",
       " ['fightback', 0.0],\n",
       " ['figur', 0.0],\n",
       " ['file', 0.0],\n",
       " ['filibust', 0.0],\n",
       " ['filipina', 0.0],\n",
       " ['filipino', 0.0],\n",
       " ['fill', 0.0],\n",
       " ['fin', 0.0],\n",
       " ['final', 0.0],\n",
       " ['financ', 0.0],\n",
       " ['financi', 0.0],\n",
       " ['find', 0.0],\n",
       " ['fine', 0.0],\n",
       " ['finger', 0.0],\n",
       " ['finish', 0.0],\n",
       " ['finnish', 0.0],\n",
       " ['fighter', 0.0],\n",
       " ['fight', 0.0],\n",
       " ['firefight', 0.0],\n",
       " ['fiercer', 0.0],\n",
       " ['felon', 0.0],\n",
       " ['feloni', 0.0],\n",
       " ['felt', 0.0],\n",
       " ['femal', 0.0],\n",
       " ['fervor', 0.0],\n",
       " ['feud', 0.0],\n",
       " ['ffa', 0.0],\n",
       " ['ffbfe', 0.0],\n",
       " ['ffca', 0.0],\n",
       " ['ffe', 0.0],\n",
       " ['ffecfa', 0.0],\n",
       " ['fi', 0.0],\n",
       " ['fiance', 0.0],\n",
       " ['field', 0.0],\n",
       " ['fierc', 0.0],\n",
       " ['fire', 0.0],\n",
       " ['firework', 0.0],\n",
       " ['feinstein', 0.0],\n",
       " ['flew', 0.0],\n",
       " ['flight', 0.0],\n",
       " ['flock', 0.0],\n",
       " ['flood', 0.0],\n",
       " ['floodwat', 0.0],\n",
       " ['floor', 0.0],\n",
       " ['florida', 0.0],\n",
       " ['flossi', 0.0],\n",
       " ['flower', 0.0],\n",
       " ['flu', 0.0],\n",
       " ['fluke', 0.0],\n",
       " ['fma', 0.0],\n",
       " ['fncynjr', 0.0],\n",
       " ['fndirev', 0.0],\n",
       " ['fnhifq', 0.0],\n",
       " ['fniism', 0.0],\n",
       " ['fli', 0.0],\n",
       " ['flee', 0.0],\n",
       " ['firm', 0.0],\n",
       " ['flaw', 0.0],\n",
       " ['first', 0.0],\n",
       " ['fisa', 0.0],\n",
       " ['fiscal', 0.0],\n",
       " ['fish', 0.0],\n",
       " ['fisher', 0.0],\n",
       " ['fit', 0.0],\n",
       " ['fitchburg', 0.0],\n",
       " ['fitow', 0.0],\n",
       " ['five', 0.0],\n",
       " ['fix', 0.0],\n",
       " ['fla', 0.0],\n",
       " ['flag', 0.0],\n",
       " ['flap', 0.0],\n",
       " ['flare', 0.0],\n",
       " ['flash', 0.0],\n",
       " ['fellow', 0.0],\n",
       " ['fefdecf', 0.0],\n",
       " ['facil', 0.0],\n",
       " ['fall', 0.0],\n",
       " ['fals', 0.0],\n",
       " ['famili', 0.0],\n",
       " ['famou', 0.0],\n",
       " ['fanni', 0.0],\n",
       " ['far', 0.0],\n",
       " ['farc', 0.0],\n",
       " ['farewel', 0.0],\n",
       " ['farlam', 0.0],\n",
       " ['farm', 0.0],\n",
       " ['farmer', 0.0],\n",
       " ['fashion', 0.0],\n",
       " ['fast', 0.0],\n",
       " ['faster', 0.0],\n",
       " ['fat', 0.0],\n",
       " ['fatal', 0.0],\n",
       " ['fallen', 0.0],\n",
       " ['fake', 0.0],\n",
       " ['fateh', 0.0],\n",
       " ['faith', 0.0],\n",
       " ['fact', 0.0],\n",
       " ['factbox', 0.0],\n",
       " ['factori', 0.0],\n",
       " ['fade', 0.0],\n",
       " ['fae', 0.0],\n",
       " ['faebec', 0.0],\n",
       " ['faedc', 0.0],\n",
       " ['fafda', 0.0],\n",
       " ['faffcd', 0.0],\n",
       " ['fager', 0.0],\n",
       " ['fail', 0.0],\n",
       " ['failur', 0.0],\n",
       " ['fair', 0.0],\n",
       " ['fairholm', 0.0],\n",
       " ['fairmont', 0.0],\n",
       " ['fate', 0.0],\n",
       " ['father', 0.0],\n",
       " ['fefa', 0.0],\n",
       " ['fe', 0.0],\n",
       " ['feadeadc', 0.0],\n",
       " ['fear', 0.0],\n",
       " ['feather', 0.0],\n",
       " ['featur', 0.0],\n",
       " ['feb', 0.0],\n",
       " ['fec', 0.0],\n",
       " ['feceb', 0.0],\n",
       " ['fed', 0.0],\n",
       " ['feder', 0.0],\n",
       " ['fedex', 0.0],\n",
       " ['fee', 0.0],\n",
       " ['feec', 0.0],\n",
       " ['feed', 0.0],\n",
       " ['feefcfa', 0.0],\n",
       " ['feel', 0.0],\n",
       " ['fea', 0.0],\n",
       " ['fdeb', 0.0],\n",
       " ['fault', 0.0],\n",
       " ['fda', 0.0],\n",
       " ['favela', 0.0],\n",
       " ['favor', 0.0],\n",
       " ['favorit', 0.0],\n",
       " ['fba', 0.0],\n",
       " ['fbaab', 0.0],\n",
       " ['fbebfa', 0.0],\n",
       " ['fbfadef', 0.0],\n",
       " ['fbffbe', 0.0],\n",
       " ['fbi', 0.0],\n",
       " ['fca', 0.0],\n",
       " ['fcaa', 0.0],\n",
       " ['fcab', 0.0],\n",
       " ['fcdabb', 0.0],\n",
       " ['fcdfa', 0.0],\n",
       " ['fcef', 0.0],\n",
       " ['egyptislamist', 0.0],\n",
       " ['egypt', 0.0],\n",
       " ['fniithn', 0.0],\n",
       " ['director', 0.0],\n",
       " ['dine', 0.0],\n",
       " ['dinner', 0.0],\n",
       " ['dio', 0.0],\n",
       " ['dip', 0.0],\n",
       " ['diplomaci', 0.0],\n",
       " ['diplomat', 0.0],\n",
       " ['direct', 0.0],\n",
       " ['dirti', 0.0],\n",
       " ['egg', 0.0],\n",
       " ['disabl', 0.0],\n",
       " ['disagre', 0.0],\n",
       " ['disappear', 0.0],\n",
       " ['disappoint', 0.0],\n",
       " ['disarma', 0.0],\n",
       " ['disarray', 0.0],\n",
       " ['disast', 0.0],\n",
       " ['dime', 0.0],\n",
       " ['dilemma', 0.0],\n",
       " ['digit', 0.0],\n",
       " ['dig', 0.0],\n",
       " ['dfa', 0.0],\n",
       " ['dfaefaa', 0.0],\n",
       " ['dfe', 0.0],\n",
       " ['dfea', 0.0],\n",
       " ['dfee', 0.0],\n",
       " ['dial', 0.0],\n",
       " ['dialogu', 0.0],\n",
       " ['diamond', 0.0],\n",
       " ['diari', 0.0],\n",
       " ['dickerson', 0.0],\n",
       " ['dictat', 0.0],\n",
       " ['didnt', 0.0],\n",
       " ['die', 0.0],\n",
       " ['diego', 0.0],\n",
       " ['difficult', 0.0],\n",
       " ['discharg', 0.0],\n",
       " ['disclos', 0.0],\n",
       " ['disclosur', 0.0],\n",
       " ['disrupt', 0.0],\n",
       " ['dissent', 0.0],\n",
       " ['dissolut', 0.0],\n",
       " ['dissolv', 0.0],\n",
       " ['distant', 0.0],\n",
       " ['distast', 0.0],\n",
       " ['distract', 0.0],\n",
       " ['district', 0.0],\n",
       " ['disturb', 0.0],\n",
       " ['dither', 0.0],\n",
       " ['diver', 0.0],\n",
       " ['divers', 0.0],\n",
       " ['divert', 0.0],\n",
       " ['divid', 0.0],\n",
       " ['divis', 0.0],\n",
       " ['dkaim', 0.0],\n",
       " ['dissect', 0.0],\n",
       " ['disrepair', 0.0],\n",
       " ['discount', 0.0],\n",
       " ['disput', 0.0],\n",
       " ['discov', 0.0],\n",
       " ['discrimin', 0.0],\n",
       " ['discuss', 0.0],\n",
       " ['diseas', 0.0],\n",
       " ['disgust', 0.0],\n",
       " ['justic', 0.0],\n",
       " ['dish', 0.0],\n",
       " ['disk', 0.0],\n",
       " ['dislik', 0.0],\n",
       " ['dismal', 0.0],\n",
       " ['dismantl', 0.0],\n",
       " ['dismiss', 0.0],\n",
       " ['dispatch', 0.0],\n",
       " ['displac', 0.0],\n",
       " ['display', 0.0],\n",
       " ['devyani', 0.0],\n",
       " ['devote', 0.0],\n",
       " ['devic', 0.0],\n",
       " ['definit', 0.0],\n",
       " ['del', 0.0],\n",
       " ['delay', 0.0],\n",
       " ['delhi', 0.0],\n",
       " ['deliber', 0.0],\n",
       " ['delic', 0.0],\n",
       " ['deliv', 0.0],\n",
       " ['dell', 0.0],\n",
       " ['dem', 0.0],\n",
       " ['demand', 0.0],\n",
       " ['demilitar', 0.0],\n",
       " ['demo', 0.0],\n",
       " ['democrat', 0.0],\n",
       " ['demolish', 0.0],\n",
       " ['demolit', 0.0],\n",
       " ['demonstr', 0.0],\n",
       " ['defrock', 0.0],\n",
       " ['defin', 0.0],\n",
       " ['denial', 0.0],\n",
       " ['deficit', 0.0],\n",
       " ['deduct', 0.0],\n",
       " ['dee', 0.0],\n",
       " ['deep', 0.0],\n",
       " ['deepen', 0.0],\n",
       " ['deepli', 0.0],\n",
       " ['defac', 0.0],\n",
       " ['default', 0.0],\n",
       " ['defeat', 0.0],\n",
       " ['defect', 0.0],\n",
       " ['defenc', 0.0],\n",
       " ['defend', 0.0],\n",
       " ['defens', 0.0],\n",
       " ['defer', 0.0],\n",
       " ['defi', 0.0],\n",
       " ['defiant', 0.0],\n",
       " ['deni', 0.0],\n",
       " ['denounc', 0.0],\n",
       " ['deviant', 0.0],\n",
       " ['desk', 0.0],\n",
       " ['despit', 0.0],\n",
       " ['destin', 0.0],\n",
       " ['destroy', 0.0],\n",
       " ['destruct', 0.0],\n",
       " ['detail', 0.0],\n",
       " ['detain', 0.0],\n",
       " ['detaine', 0.0],\n",
       " ['detect', 0.0],\n",
       " ['detent', 0.0],\n",
       " ['deter', 0.0],\n",
       " ['deterior', 0.0],\n",
       " ['deterr', 0.0],\n",
       " ['detroit', 0.0],\n",
       " ['devast', 0.0],\n",
       " ['develop', 0.0],\n",
       " ['desper', 0.0],\n",
       " ['design', 0.0],\n",
       " ['densiti', 0.0],\n",
       " ['desh', 0.0],\n",
       " ['dental', 0.0],\n",
       " ['denton', 0.0],\n",
       " ['depart', 0.0],\n",
       " ['deplor', 0.0],\n",
       " ['deport', 0.0],\n",
       " ['depress', 0.0],\n",
       " ['dept', 0.0],\n",
       " ['depth', 0.0],\n",
       " ['deputi', 0.0],\n",
       " ['der', 0.0],\n",
       " ['derail', 0.0],\n",
       " ['derrick', 0.0],\n",
       " ['describ', 0.0],\n",
       " ['desert', 0.0],\n",
       " ['deserv', 0.0],\n",
       " ['dna', 0.0],\n",
       " ['doctor', 0.0],\n",
       " ['document', 0.0],\n",
       " ['ebbcf', 0.0],\n",
       " ['ebf', 0.0],\n",
       " ['ebfb', 0.0],\n",
       " ['ebrd', 0.0],\n",
       " ['ec', 0.0],\n",
       " ['ecabec', 0.0],\n",
       " ['eccbdc', 0.0],\n",
       " ['eccccab', 0.0],\n",
       " ['ecf', 0.0],\n",
       " ['ecffcb', 0.0],\n",
       " ['econom', 0.0],\n",
       " ['economi', 0.0],\n",
       " ['economist', 0.0],\n",
       " ['ecuador', 0.0],\n",
       " ['ecuadorean', 0.0],\n",
       " ['ed', 0.0],\n",
       " ['ebe', 0.0],\n",
       " ['ebbaf', 0.0],\n",
       " ['edc', 0.0],\n",
       " ['ebba', 0.0],\n",
       " ['eager', 0.0],\n",
       " ['eagl', 0.0],\n",
       " ['earli', 0.0],\n",
       " ['earlier', 0.0],\n",
       " ['earn', 0.0],\n",
       " ['earth', 0.0],\n",
       " ['earthquak', 0.0],\n",
       " ['eas', 0.0],\n",
       " ['east', 0.0],\n",
       " ['eastern', 0.0],\n",
       " ['eat', 0.0],\n",
       " ['eavesdrop', 0.0],\n",
       " ['eb', 0.0],\n",
       " ['ebay', 0.0],\n",
       " ['ebb', 0.0],\n",
       " ['edb', 0.0],\n",
       " ['edcfa', 0.0],\n",
       " ['eaf', 0.0],\n",
       " ['efb', 0.0],\n",
       " ['efbbbb', 0.0],\n",
       " ['efc', 0.0],\n",
       " ['efcceb', 0.0],\n",
       " ['efd', 0.0],\n",
       " ['efe', 0.0],\n",
       " ['effbff', 0.0],\n",
       " ['effc', 0.0],\n",
       " ['effect', 0.0],\n",
       " ['effort', 0.0],\n",
       " ['efreau', 0.0],\n",
       " ['efrfku', 0.0],\n",
       " ['efrfkui', 0.0],\n",
       " ['efrfkur', 0.0],\n",
       " ['efrfro', 0.0],\n",
       " ['egan', 0.0],\n",
       " ['efbafaf', 0.0],\n",
       " ['efaefcb', 0.0],\n",
       " ['edf', 0.0],\n",
       " ['efa', 0.0],\n",
       " ['edfdca', 0.0],\n",
       " ['edffefb', 0.0],\n",
       " ['edg', 0.0],\n",
       " ['editori', 0.0],\n",
       " ['edmundson', 0.0],\n",
       " ['edt', 0.0],\n",
       " ['educ', 0.0],\n",
       " ['edward', 0.0],\n",
       " ['eeb', 0.0],\n",
       " ['eebd', 0.0],\n",
       " ['eec', 0.0],\n",
       " ['eecfbbadfc', 0.0],\n",
       " ['eed', 0.0],\n",
       " ['eefaa', 0.0],\n",
       " ['ef', 0.0],\n",
       " ['eafc', 0.0],\n",
       " ['eaeabb', 0.0],\n",
       " ['dodger', 0.0],\n",
       " ['doomsday', 0.0],\n",
       " ['dormic', 0.0],\n",
       " ['dot', 0.0],\n",
       " ['doubl', 0.0],\n",
       " ['doubt', 0.0],\n",
       " ['dover', 0.0],\n",
       " ['downplay', 0.0],\n",
       " ['downstream', 0.0],\n",
       " ['dowri', 0.0],\n",
       " ['dozen', 0.0],\n",
       " ['draft', 0.0],\n",
       " ['drag', 0.0],\n",
       " ['drama', 0.0],\n",
       " ['draw', 0.0],\n",
       " ['drawn', 0.0],\n",
       " ['dream', 0.0],\n",
       " ['dope', 0.0],\n",
       " ['doom', 0.0],\n",
       " ['dress', 0.0],\n",
       " ['doolittl', 0.0],\n",
       " ['doe', 0.0],\n",
       " ['doesnt', 0.0],\n",
       " ['dog', 0.0],\n",
       " ['doha', 0.0],\n",
       " ['doj', 0.0],\n",
       " ['dol', 0.0],\n",
       " ['doll', 0.0],\n",
       " ['dollar', 0.0],\n",
       " ['dolphin', 0.0],\n",
       " ['domin', 0.0],\n",
       " ['donald', 0.0],\n",
       " ['donat', 0.0],\n",
       " ['done', 0.0],\n",
       " ['donor', 0.0],\n",
       " ['dont', 0.0],\n",
       " ['dreamlin', 0.0],\n",
       " ['dri', 0.0],\n",
       " ['ead', 0.0],\n",
       " ['dudzick', 0.0],\n",
       " ['dui', 0.0],\n",
       " ['duke', 0.0],\n",
       " ['dumb', 0.0],\n",
       " ['dumbarton', 0.0],\n",
       " ['dump', 0.0],\n",
       " ['duo', 0.0],\n",
       " ['durham', 0.0],\n",
       " ['dustin', 0.0],\n",
       " ['dutch', 0.0],\n",
       " ['dwindl', 0.0],\n",
       " ['dye', 0.0],\n",
       " ['dynasti', 0.0],\n",
       " ['ea', 0.0],\n",
       " ['eaa', 0.0],\n",
       " ['eaaac', 0.0],\n",
       " ['due', 0.0],\n",
       " ['dudek', 0.0],\n",
       " ['drill', 0.0],\n",
       " ['duckfat', 0.0],\n",
       " ['drink', 0.0],\n",
       " ['driscol', 0.0],\n",
       " ['drive', 0.0],\n",
       " ['driver', 0.0],\n",
       " ['drone', 0.0],\n",
       " ['drop', 0.0],\n",
       " ['drove', 0.0],\n",
       " ['drown', 0.0],\n",
       " ['drug', 0.0],\n",
       " ['drunk', 0.0],\n",
       " ['drunken', 0.0],\n",
       " ['dual', 0.0],\n",
       " ['dubai', 0.0],\n",
       " ['duchess', 0.0],\n",
       " ['duck', 0.0],\n",
       " ['fniisx', 0.0],\n",
       " ['fniivw', 0.0],\n",
       " ['juic', 0.0],\n",
       " ['icahn', 0.0],\n",
       " ['hvu', 0.0],\n",
       " ['hydraul', 0.0],\n",
       " ['hydrocodon', 0.0],\n",
       " ['hypocrisi', 0.0],\n",
       " ['iaeoklgupuphfh', 0.0],\n",
       " ['ibrahim', 0.0],\n",
       " ['icac', 0.0],\n",
       " ['icc', 0.0],\n",
       " ['henderson', 0.0],\n",
       " ['ice', 0.0],\n",
       " ['id', 0.0],\n",
       " ['idaho', 0.0],\n",
       " ['idahoan', 0.0],\n",
       " ['idd', 0.0],\n",
       " ['identifi', 0.0],\n",
       " ['idinbrebvn', 0.0],\n",
       " ['hurt', 0.0],\n",
       " ['hurrican', 0.0],\n",
       " ['hurdl', 0.0],\n",
       " ['hunter', 0.0],\n",
       " ['huawei', 0.0],\n",
       " ['hub', 0.0],\n",
       " ['huddl', 0.0],\n",
       " ['hudson', 0.0],\n",
       " ['huffington', 0.0],\n",
       " ['hug', 0.0],\n",
       " ['huge', 0.0],\n",
       " ['hulk', 0.0],\n",
       " ['human', 0.0],\n",
       " ['humanitarian', 0.0],\n",
       " ['humbl', 0.0],\n",
       " ['hummingbird', 0.0],\n",
       " ['hundr', 0.0],\n",
       " ['hungri', 0.0],\n",
       " ['hunt', 0.0],\n",
       " ['idinln', 0.0],\n",
       " ['idinlnhjq', 0.0],\n",
       " ['idinlnicv', 0.0],\n",
       " ['implic', 0.0],\n",
       " ['impot', 0.0],\n",
       " ['imprison', 0.0],\n",
       " ['impromptu', 0.0],\n",
       " ['improv', 0.0],\n",
       " ['impuls', 0.0],\n",
       " ['imxnbevapp', 0.0],\n",
       " ['in', 0.0],\n",
       " ['inadequ', 0.0],\n",
       " ['inaugur', 0.0],\n",
       " ['inc', 0.0],\n",
       " ['inch', 0.0],\n",
       " ['incid', 0.0],\n",
       " ['includ', 0.0],\n",
       " ['increas', 0.0],\n",
       " ['increasingli', 0.0],\n",
       " ['import', 0.0],\n",
       " ['impass', 0.0],\n",
       " ['idinlnkyf', 0.0],\n",
       " ['impal', 0.0],\n",
       " ['ifprdjzhatro', 0.0],\n",
       " ['ignor', 0.0],\n",
       " ['igp', 0.0],\n",
       " ['ikea', 0.0],\n",
       " ['ill', 0.0],\n",
       " ['illeg', 0.0],\n",
       " ['illinoi', 0.0],\n",
       " ['illus', 0.0],\n",
       " ['imag', 0.0],\n",
       " ['imf', 0.0],\n",
       " ['immigr', 0.0],\n",
       " ['immin', 0.0],\n",
       " ['immol', 0.0],\n",
       " ['immun', 0.0],\n",
       " ['impact', 0.0],\n",
       " ['hoyal', 0.0],\n",
       " ['hover', 0.0],\n",
       " ['houston', 0.0],\n",
       " ['hike', 0.0],\n",
       " ['hillari', 0.0],\n",
       " ['hinder', 0.0],\n",
       " ['hindu', 0.0],\n",
       " ['hint', 0.0],\n",
       " ['hip', 0.0],\n",
       " ['hippi', 0.0],\n",
       " ['hire', 0.0],\n",
       " ['histor', 0.0],\n",
       " ['histori', 0.0],\n",
       " ['hit', 0.0],\n",
       " ['hitch', 0.0],\n",
       " ['hitler', 0.0],\n",
       " ['hiv', 0.0],\n",
       " ['hizbollah', 0.0],\n",
       " ['ho', 0.0],\n",
       " ['hill', 0.0],\n",
       " ['hijack', 0.0],\n",
       " ['hoffman', 0.0],\n",
       " ['hijab', 0.0],\n",
       " ['herald', 0.0],\n",
       " ['here', 0.0],\n",
       " ['heritag', 0.0],\n",
       " ['hero', 0.0],\n",
       " ['heroin', 0.0],\n",
       " ['herrera', 0.0],\n",
       " ['hezbollah', 0.0],\n",
       " ['hidden', 0.0],\n",
       " ['hide', 0.0],\n",
       " ['hideout', 0.0],\n",
       " ['high', 0.0],\n",
       " ['higher', 0.0],\n",
       " ['highest', 0.0],\n",
       " ['highlight', 0.0],\n",
       " ['highway', 0.0],\n",
       " ['hobbl', 0.0],\n",
       " ['hogan', 0.0],\n",
       " ['housem', 0.0],\n",
       " ['honor', 0.0],\n",
       " ['hood', 0.0],\n",
       " ['hook', 0.0],\n",
       " ['hooker', 0.0],\n",
       " ['hop', 0.0],\n",
       " ['hope', 0.0],\n",
       " ['hosni', 0.0],\n",
       " ['hospit', 0.0],\n",
       " ['host', 0.0],\n",
       " ['hostag', 0.0],\n",
       " ['hostess', 0.0],\n",
       " ['hostil', 0.0],\n",
       " ['hot', 0.0],\n",
       " ['hotel', 0.0],\n",
       " ['hour', 0.0],\n",
       " ['hous', 0.0],\n",
       " ['honour', 0.0],\n",
       " ['honolulu', 0.0],\n",
       " ['hold', 0.0],\n",
       " ['hong', 0.0],\n",
       " ['holder', 0.0],\n",
       " ['holi', 0.0],\n",
       " ['holiday', 0.0],\n",
       " ['hollow', 0.0],\n",
       " ['hollywood', 0.0],\n",
       " ['holm', 0.0],\n",
       " ['home', 0.0],\n",
       " ['homebuy', 0.0],\n",
       " ['homeland', 0.0],\n",
       " ['homeless', 0.0],\n",
       " ['homemad', 0.0],\n",
       " ['homicid', 0.0],\n",
       " ['homosexu', 0.0],\n",
       " ['hondura', 0.0],\n",
       " ['honest', 0.0],\n",
       " ['ind', 0.0],\n",
       " ['independ', 0.0],\n",
       " ['index', 0.0],\n",
       " ['item', 0.0],\n",
       " ['ivori', 0.0],\n",
       " ['ix', 0.0],\n",
       " ['izhvi', 0.0],\n",
       " ['jackson', 0.0],\n",
       " ['jacksonvil', 0.0],\n",
       " ['jahi', 0.0],\n",
       " ['jail', 0.0],\n",
       " ['jal', 0.0],\n",
       " ['jamaat', 0.0],\n",
       " ['jamaica', 0.0],\n",
       " ['jame', 0.0],\n",
       " ['janet', 0.0],\n",
       " ['japan', 0.0],\n",
       " ['japanes', 0.0],\n",
       " ['jasper', 0.0],\n",
       " ['iuzbkteo', 0.0],\n",
       " ['italian', 0.0],\n",
       " ['jazeera', 0.0],\n",
       " ['itali', 0.0],\n",
       " ['iron', 0.0],\n",
       " ['ironi', 0.0],\n",
       " ['irrefut', 0.0],\n",
       " ['irrepress', 0.0],\n",
       " ['irvin', 0.0],\n",
       " ['isdktgidhotab', 0.0],\n",
       " ['isl', 0.0],\n",
       " ['islam', 0.0],\n",
       " ['islami', 0.0],\n",
       " ['islamist', 0.0],\n",
       " ['island', 0.0],\n",
       " ['ison', 0.0],\n",
       " ['isra', 0.0],\n",
       " ['israel', 0.0],\n",
       " ['issu', 0.0],\n",
       " ['jayden', 0.0],\n",
       " ['jazz', 0.0],\n",
       " ['iraqi', 0.0],\n",
       " ['joint', 0.0],\n",
       " ['joliet', 0.0],\n",
       " ['jolt', 0.0],\n",
       " ['jon', 0.0],\n",
       " ['jone', 0.0],\n",
       " ['joplin', 0.0],\n",
       " ['jordan', 0.0],\n",
       " ['joseph', 0.0],\n",
       " ['journalist', 0.0],\n",
       " ['journey', 0.0],\n",
       " ['joy', 0.0],\n",
       " ['jpha', 0.0],\n",
       " ['jpmorgan', 0.0],\n",
       " ['judg', 0.0],\n",
       " ['judici', 0.0],\n",
       " ['judith', 0.0],\n",
       " ['joke', 0.0],\n",
       " ['join', 0.0],\n",
       " ['jean', 0.0],\n",
       " ['john', 0.0],\n",
       " ['jeep', 0.0],\n",
       " ['jeff', 0.0],\n",
       " ['jeffrey', 0.0],\n",
       " ['jeopard', 0.0],\n",
       " ['jersey', 0.0],\n",
       " ['jerusalem', 0.0],\n",
       " ['jess', 0.0],\n",
       " ['jesu', 0.0],\n",
       " ['jet', 0.0],\n",
       " ['jihadi', 0.0],\n",
       " ['jo', 0.0],\n",
       " ['joan', 0.0],\n",
       " ['joaquin', 0.0],\n",
       " ['job', 0.0],\n",
       " ['jofi', 0.0],\n",
       " ['ireland', 0.0],\n",
       " ['iraq', 0.0],\n",
       " ['india', 0.0],\n",
       " ['inject', 0.0],\n",
       " ['injuri', 0.0],\n",
       " ['injustic', 0.0],\n",
       " ['ink', 0.0],\n",
       " ['inmat', 0.0],\n",
       " ['innoc', 0.0],\n",
       " ['innov', 0.0],\n",
       " ['inquiri', 0.0],\n",
       " ['insan', 0.0],\n",
       " ['insid', 0.0],\n",
       " ['insist', 0.0],\n",
       " ['inspect', 0.0],\n",
       " ['inspector', 0.0],\n",
       " ['inspir', 0.0],\n",
       " ['instal', 0.0],\n",
       " ['institut', 0.0],\n",
       " ['injur', 0.0],\n",
       " ['initiat', 0.0],\n",
       " ['insult', 0.0],\n",
       " ['initi', 0.0],\n",
       " ['indian', 0.0],\n",
       " ['indiana', 0.0],\n",
       " ['indic', 0.0],\n",
       " ['indict', 0.0],\n",
       " ['indo', 0.0],\n",
       " ['indonesia', 0.0],\n",
       " ['industri', 0.0],\n",
       " ['inequ', 0.0],\n",
       " ['inexcus', 0.0],\n",
       " ['infect', 0.0],\n",
       " ['inferno', 0.0],\n",
       " ['info', 0.0],\n",
       " ['inform', 0.0],\n",
       " ['ingredi', 0.0],\n",
       " ['inhof', 0.0],\n",
       " ['instructor', 0.0],\n",
       " ['insur', 0.0],\n",
       " ['iranian', 0.0],\n",
       " ['intox', 0.0],\n",
       " ['intrud', 0.0],\n",
       " ['jump', 0.0],\n",
       " ['intrus', 0.0],\n",
       " ['invest', 0.0],\n",
       " ['investig', 0.0],\n",
       " ['investor', 0.0],\n",
       " ['invit', 0.0],\n",
       " ['involv', 0.0],\n",
       " ['inyemen', 0.0],\n",
       " ['iowa', 0.0],\n",
       " ['ip', 0.0],\n",
       " ['ipad', 0.0],\n",
       " ['iphon', 0.0],\n",
       " ['ir', 0.0],\n",
       " ['iran', 0.0],\n",
       " ['introduc', 0.0],\n",
       " ['interview', 0.0],\n",
       " ['insurg', 0.0],\n",
       " ['intervent', 0.0],\n",
       " ['integr', 0.0],\n",
       " ['intel', 0.0],\n",
       " ['intellectu', 0.0],\n",
       " ['intellig', 0.0],\n",
       " ['intent', 0.0],\n",
       " ['intercept', 0.0],\n",
       " ['intercompani', 0.0],\n",
       " ['interest', 0.0],\n",
       " ['interfer', 0.0],\n",
       " ['interim', 0.0],\n",
       " ['intermountain', 0.0],\n",
       " ['intern', 0.0],\n",
       " ['internet', 0.0],\n",
       " ['interpol', 0.0],\n",
       " ['interrog', 0.0],\n",
       " ['henni', 0.0],\n",
       " ['hemp', 0.0],\n",
       " ['fniiyv', 0.0],\n",
       " ['garnett', 0.0],\n",
       " ['game', 0.0],\n",
       " ['gang', 0.0],\n",
       " ['gangrap', 0.0],\n",
       " ['ganja', 0.0],\n",
       " ['gap', 0.0],\n",
       " ['garcetti', 0.0],\n",
       " ['garner', 0.0],\n",
       " ['gaslin', 0.0],\n",
       " ['help', 0.0],\n",
       " ['gate', 0.0],\n",
       " ['gather', 0.0],\n",
       " ['gave', 0.0],\n",
       " ['gaxhjuni', 0.0],\n",
       " ['gay', 0.0],\n",
       " ['gaz', 0.0],\n",
       " ['gaza', 0.0],\n",
       " ['juri', 0.0],\n",
       " ['gambl', 0.0],\n",
       " ['gambit', 0.0],\n",
       " ['gallon', 0.0],\n",
       " ['full', 0.0],\n",
       " ['fulli', 0.0],\n",
       " ['fund', 0.0],\n",
       " ['fundrais', 0.0],\n",
       " ['funer', 0.0],\n",
       " ['furi', 0.0],\n",
       " ['furlough', 0.0],\n",
       " ['fuse', 0.0],\n",
       " ['futur', 0.0],\n",
       " ['ga', 0.0],\n",
       " ['gadget', 0.0],\n",
       " ['gaga', 0.0],\n",
       " ['gain', 0.0],\n",
       " ['gal', 0.0],\n",
       " ['galleri', 0.0],\n",
       " ['gazett', 0.0],\n",
       " ['ge', 0.0],\n",
       " ['gear', 0.0],\n",
       " ['giraldi', 0.0],\n",
       " ['gismweckwz', 0.0],\n",
       " ['gitmo', 0.0],\n",
       " ['give', 0.0],\n",
       " ['giveaway', 0.0],\n",
       " ['given', 0.0],\n",
       " ['glass', 0.0],\n",
       " ['glich', 0.0],\n",
       " ['glitch', 0.0],\n",
       " ['global', 0.0],\n",
       " ['globe', 0.0],\n",
       " ['gmail', 0.0],\n",
       " ['go', 0.0],\n",
       " ['goa', 0.0],\n",
       " ['goal', 0.0],\n",
       " ['goe', 0.0],\n",
       " ['girl', 0.0],\n",
       " ['gingrich', 0.0],\n",
       " ['geiss', 0.0],\n",
       " ['gilroy', 0.0],\n",
       " ['gener', 0.0],\n",
       " ['geneva', 0.0],\n",
       " ['geniu', 0.0],\n",
       " ['genocid', 0.0],\n",
       " ['geographi', 0.0],\n",
       " ['georg', 0.0],\n",
       " ['georgia', 0.0],\n",
       " ['german', 0.0],\n",
       " ['germani', 0.0],\n",
       " ['get', 0.0],\n",
       " ['gettysburg', 0.0],\n",
       " ['gi', 0.0],\n",
       " ['giant', 0.0],\n",
       " ['gibney', 0.0],\n",
       " ['gift', 0.0],\n",
       " ['fulfil', 0.0],\n",
       " ['fukushima', 0.0],\n",
       " ...]"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab=aa[0]#model.coef_[0]\n",
    "[[key_cols[i],ab[i]] for i in np.argsort(abs(ab))[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [1.0, 0.77187932464248254, 0.87119529697081077] avg_validation_rec,prec,F1: [0.97070707070707074, 0.62297619047619035, 0.75461295226512615]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'apriltodectfidf','logreg',['l1',0.095],10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [0.93333333333333335, 0.3888888888888889, 0.5490196078431373]\n"
     ]
    }
   ],
   "source": [
    "aa=predictorgdelt.kfold_test_class('apriltodectfidf','logreg',['l1',0.095],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictorgdelt.ydata['apriltodectfidf'][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.yhat_class['apriltodectfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_rec,prec,F1: [0.99316945840049764, 0.87472075977840691, 0.93013643870901608] avg_validation_rec,prec,F1: [0.78934065934065933, 0.60476190476190483, 0.65097784615687426]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_val_class(10,'7daystfidf','svclass',[0.01,'poly'],10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rec,prec,F1: [0.69230769230769229, 0.75, 0.71999999999999986]\n"
     ]
    }
   ],
   "source": [
    "predictorgdelt.kfold_test_class('7daystfidf','svclass',[0.01,'poly'],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.yhat_class['7daystfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorgdelt.ydata['7daystfidf'][1][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#downloading and unzipping, run at your own risk, contains dreadful shell commands\n",
    "for date in range(20131001,20131032):\n",
    "    os.system('wget http://data.gdeltproject.org/events/'+str(date)+'.export.CSV.zip')\n",
    "    os.system('unzip '+str(date)+'.export.CSV.zip')\n",
    "    os.system('mv '+str(date)+'.export.CSV data/GDELT_1.0')\n",
    "    os.system('rm '+str(date)+'.export.CSV.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Maxos  staff    10M May 20  2013 data/GDELT_1.0/20130401.export.CSV\r\n"
     ]
    }
   ],
   "source": [
    "!ls -hl data/GDELT_1.0/20130401.export.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_daily=pd.read_csv('../data/GDELT_1.0/CSV.header.dailyupdates.txt',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>Year</th>\n",
       "      <th>FractionDate</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor1KnownGroupCode</th>\n",
       "      <th>Actor1EthnicCode</th>\n",
       "      <th>...</th>\n",
       "      <th>Actor2Geo_FeatureID</th>\n",
       "      <th>ActionGeo_Type</th>\n",
       "      <th>ActionGeo_FullName</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>DATEADDED</th>\n",
       "      <th>SOURCEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253461012</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AS</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>-27.0000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>AS</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bangkokpost.com/breakingnews/343522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253461013</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>BUS</td>\n",
       "      <td>SHOP OWNER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>4</td>\n",
       "      <td>Tai Hang, Hong Kong (general), Hong Kong</td>\n",
       "      <td>HK</td>\n",
       "      <td>HK00</td>\n",
       "      <td>22.4667</td>\n",
       "      <td>114.150</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bloomberg.com/news/2013-04-01/hong-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253461014</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>BUS</td>\n",
       "      <td>SHOP OWNER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1354454</td>\n",
       "      <td>4</td>\n",
       "      <td>Tai Hang, Hong Kong (general), Hong Kong</td>\n",
       "      <td>HK</td>\n",
       "      <td>HK00</td>\n",
       "      <td>22.4667</td>\n",
       "      <td>114.150</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bloomberg.com/news/2013-04-01/hong-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253461015</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>CVL</td>\n",
       "      <td>MIGRANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AS</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>-27.0000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>AS</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bangkokpost.com/breakingnews/343522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253461016</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>HLH</td>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Nevada, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USNV</td>\n",
       "      <td>38.4199</td>\n",
       "      <td>-117.122</td>\n",
       "      <td>NV</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.startribune.com/nation/200818961.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLOBALEVENTID   SQLDATE  MonthYear  Year  FractionDate Actor1Code  \\\n",
       "0      253461012  20030404     200304  2003     2003.2575        AUS   \n",
       "1      253461013  20030404     200304  2003     2003.2575        BUS   \n",
       "2      253461014  20030404     200304  2003     2003.2575        BUS   \n",
       "3      253461015  20030404     200304  2003     2003.2575        CVL   \n",
       "4      253461016  20030404     200304  2003     2003.2575        HLH   \n",
       "\n",
       "   Actor1Name Actor1CountryCode Actor1KnownGroupCode Actor1EthnicCode  \\\n",
       "0   AUSTRALIA               AUS                  NaN              NaN   \n",
       "1  SHOP OWNER               NaN                  NaN              NaN   \n",
       "2  SHOP OWNER               NaN                  NaN              NaN   \n",
       "3     MIGRANT               NaN                  NaN              NaN   \n",
       "4      DOCTOR               NaN                  NaN              NaN   \n",
       "\n",
       "                         ...                         Actor2Geo_FeatureID  \\\n",
       "0                        ...                                          AS   \n",
       "1                        ...                                    -1354145   \n",
       "2                        ...                                    -1354454   \n",
       "3                        ...                                          AS   \n",
       "4                        ...                                         NaN   \n",
       "\n",
       "  ActionGeo_Type                        ActionGeo_FullName  \\\n",
       "0              1                                 Australia   \n",
       "1              4  Tai Hang, Hong Kong (general), Hong Kong   \n",
       "2              4  Tai Hang, Hong Kong (general), Hong Kong   \n",
       "3              1                                 Australia   \n",
       "4              2                     Nevada, United States   \n",
       "\n",
       "  ActionGeo_CountryCode ActionGeo_ADM1Code ActionGeo_Lat ActionGeo_Long  \\\n",
       "0                    AS                 AS      -27.0000        133.000   \n",
       "1                    HK               HK00       22.4667        114.150   \n",
       "2                    HK               HK00       22.4667        114.150   \n",
       "3                    AS                 AS      -27.0000        133.000   \n",
       "4                    US               USNV       38.4199       -117.122   \n",
       "\n",
       "  ActionGeo_FeatureID DATEADDED  \\\n",
       "0                  AS  20130401   \n",
       "1            -1354145  20130401   \n",
       "2            -1354145  20130401   \n",
       "3                  AS  20130401   \n",
       "4                  NV  20130401   \n",
       "\n",
       "                                           SOURCEURL  \n",
       "0  http://www.bangkokpost.com/breakingnews/343522...  \n",
       "1  http://www.bloomberg.com/news/2013-04-01/hong-...  \n",
       "2  http://www.bloomberg.com/news/2013-04-01/hong-...  \n",
       "3  http://www.bangkokpost.com/breakingnews/343522...  \n",
       "4   http://www.startribune.com/nation/200818961.html  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#this is just to show what the GDELT files look like\n",
    "sample_df=pd.read_csv('../data/GDELT_1.0/20130401.export.CSV',delimiter='\\t')\n",
    "sample_df.columns=list(header_daily)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 52,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 4840,\n",
       " 4841,\n",
       " 4842,\n",
       " 4843,\n",
       " 4844,\n",
       " 4845,\n",
       " 4846,\n",
       " 4847,\n",
       " 4848,\n",
       " 4849,\n",
       " 4850,\n",
       " 4851,\n",
       " 4852,\n",
       " 4853,\n",
       " 4854,\n",
       " 4855,\n",
       " 4856,\n",
       " 4857,\n",
       " 4858,\n",
       " 4859,\n",
       " 4860,\n",
       " 4861,\n",
       " 4862,\n",
       " 4863,\n",
       " 4864,\n",
       " 4865,\n",
       " 4866,\n",
       " 4867,\n",
       " 4868,\n",
       " 4869,\n",
       " 4870,\n",
       " 4871,\n",
       " 4872,\n",
       " 4873,\n",
       " 4874,\n",
       " 4875,\n",
       " 4876,\n",
       " 4877,\n",
       " 4878,\n",
       " 4879,\n",
       " 4880,\n",
       " 4881,\n",
       " 4882,\n",
       " 4883,\n",
       " 4884,\n",
       " 4885,\n",
       " 4886,\n",
       " 4887,\n",
       " 4888,\n",
       " 4889,\n",
       " 4890,\n",
       " 4891,\n",
       " 4892,\n",
       " 4893,\n",
       " 4894,\n",
       " 4895,\n",
       " 4896,\n",
       " 4897,\n",
       " 4898,\n",
       " 4899,\n",
       " 4900,\n",
       " 4901,\n",
       " 4902,\n",
       " 4903,\n",
       " 4904,\n",
       " 4905,\n",
       " 4906,\n",
       " 4907,\n",
       " 4908,\n",
       " 4909,\n",
       " 4910,\n",
       " 4911,\n",
       " 4912,\n",
       " 4913,\n",
       " 4914,\n",
       " 4915,\n",
       " 4916,\n",
       " 4917,\n",
       " 4918,\n",
       " 4919,\n",
       " 4920,\n",
       " 4921,\n",
       " 4922,\n",
       " 4923,\n",
       " 4924,\n",
       " 4925,\n",
       " 4926,\n",
       " 4927,\n",
       " 4928,\n",
       " 4929,\n",
       " 4930,\n",
       " 4931,\n",
       " 4932,\n",
       " 4933,\n",
       " 4934,\n",
       " 4935,\n",
       " 4936,\n",
       " 4937,\n",
       " 4938,\n",
       " 4939,\n",
       " 4940,\n",
       " 4941,\n",
       " 4942,\n",
       " 4943,\n",
       " 4944,\n",
       " 4945,\n",
       " 4946,\n",
       " 4947,\n",
       " 4948,\n",
       " 4949,\n",
       " 4950,\n",
       " 4951,\n",
       " 4952,\n",
       " 4953,\n",
       " 4954,\n",
       " 4955,\n",
       " 4956,\n",
       " 4957,\n",
       " 4958,\n",
       " 4959,\n",
       " 4960,\n",
       " 4961,\n",
       " 4962,\n",
       " 4963,\n",
       " 4964,\n",
       " 4965,\n",
       " 4966,\n",
       " 4967,\n",
       " 4968,\n",
       " 4969,\n",
       " 4970,\n",
       " 4971,\n",
       " 4972,\n",
       " 4973,\n",
       " 4974,\n",
       " 4975,\n",
       " 4976,\n",
       " 4977,\n",
       " 4978,\n",
       " 4979,\n",
       " 4980,\n",
       " 4981,\n",
       " 4982,\n",
       " 4983,\n",
       " 4984,\n",
       " 4985,\n",
       " 4986,\n",
       " 4987,\n",
       " 4988,\n",
       " 4989,\n",
       " 4990,\n",
       " 4991,\n",
       " 4992,\n",
       " 4993,\n",
       " 4994,\n",
       " 4995,\n",
       " 4996,\n",
       " 4997,\n",
       " 4998,\n",
       " 4999,\n",
       " 5000,\n",
       " 5001,\n",
       " 5002,\n",
       " 5003,\n",
       " 5004,\n",
       " 5005,\n",
       " 5006,\n",
       " 5007,\n",
       " 5008,\n",
       " 5009,\n",
       " 5010,\n",
       " 5011,\n",
       " 5012,\n",
       " 5013,\n",
       " 5014,\n",
       " 5015,\n",
       " 5016,\n",
       " 5017,\n",
       " 5018,\n",
       " 5019,\n",
       " 5020,\n",
       " 5021,\n",
       " 5022,\n",
       " 5023,\n",
       " 5024,\n",
       " 5025,\n",
       " 5026,\n",
       " 5027,\n",
       " 5028,\n",
       " 5029,\n",
       " 5030,\n",
       " 5031,\n",
       " 5032,\n",
       " 5033,\n",
       " 5034,\n",
       " 5035,\n",
       " 5036,\n",
       " 5037,\n",
       " 5038,\n",
       " 5039,\n",
       " 5040,\n",
       " 5041,\n",
       " 5042,\n",
       " 5043,\n",
       " 5044,\n",
       " 5045,\n",
       " 5046,\n",
       " 5047,\n",
       " 5048,\n",
       " 5049,\n",
       " 5050,\n",
       " 5051,\n",
       " 5052,\n",
       " 5053,\n",
       " 5054,\n",
       " 5055,\n",
       " 5056,\n",
       " 5057,\n",
       " 5058,\n",
       " 5059,\n",
       " 5060,\n",
       " 5061,\n",
       " 5062,\n",
       " 5063,\n",
       " 5064,\n",
       " 5065,\n",
       " 5066,\n",
       " 5067,\n",
       " 5068,\n",
       " 5069,\n",
       " 5070,\n",
       " 5071,\n",
       " 5072,\n",
       " 5073,\n",
       " 5074,\n",
       " 5075,\n",
       " 5076,\n",
       " 5077,\n",
       " 5078,\n",
       " 5079,\n",
       " 5080,\n",
       " 5081,\n",
       " 5082,\n",
       " 5083,\n",
       " 5084,\n",
       " 5085,\n",
       " 5086,\n",
       " 5087,\n",
       " 5088,\n",
       " 5089,\n",
       " 5090,\n",
       " 5091,\n",
       " 5092,\n",
       " 5093,\n",
       " 5094,\n",
       " 5095,\n",
       " 5096,\n",
       " 5097,\n",
       " 5098,\n",
       " 5099,\n",
       " 5100,\n",
       " 5101,\n",
       " 5102,\n",
       " 5103,\n",
       " 5104,\n",
       " 5105,\n",
       " 5106,\n",
       " 5107,\n",
       " 5108,\n",
       " 5109,\n",
       " 5110,\n",
       " 5111,\n",
       " 5112,\n",
       " 5113,\n",
       " 5114,\n",
       " 5115,\n",
       " 5116,\n",
       " 5117,\n",
       " 5118,\n",
       " 5119,\n",
       " 5120]"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppers=[row_ind for row_ind in range(len(sample_df)) if sample_df.iloc[row_ind,7]=='AUS']\n",
    "droppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>Year</th>\n",
       "      <th>FractionDate</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor1KnownGroupCode</th>\n",
       "      <th>Actor1EthnicCode</th>\n",
       "      <th>...</th>\n",
       "      <th>Actor2Geo_FeatureID</th>\n",
       "      <th>ActionGeo_Type</th>\n",
       "      <th>ActionGeo_FullName</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>DATEADDED</th>\n",
       "      <th>SOURCEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253461013</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>BUS</td>\n",
       "      <td>SHOP OWNER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>4</td>\n",
       "      <td>Tai Hang, Hong Kong (general), Hong Kong</td>\n",
       "      <td>HK</td>\n",
       "      <td>HK00</td>\n",
       "      <td>22.46670</td>\n",
       "      <td>114.15000</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bloomberg.com/news/2013-04-01/hong-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253461014</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>BUS</td>\n",
       "      <td>SHOP OWNER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1354454</td>\n",
       "      <td>4</td>\n",
       "      <td>Tai Hang, Hong Kong (general), Hong Kong</td>\n",
       "      <td>HK</td>\n",
       "      <td>HK00</td>\n",
       "      <td>22.46670</td>\n",
       "      <td>114.15000</td>\n",
       "      <td>-1354145</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bloomberg.com/news/2013-04-01/hong-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253461015</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>CVL</td>\n",
       "      <td>MIGRANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AS</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>-27.00000</td>\n",
       "      <td>133.00000</td>\n",
       "      <td>AS</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bangkokpost.com/breakingnews/343522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253461016</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>HLH</td>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Nevada, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USNV</td>\n",
       "      <td>38.41990</td>\n",
       "      <td>-117.12200</td>\n",
       "      <td>NV</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.startribune.com/nation/200818961.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253461017</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>UIS</td>\n",
       "      <td>THE INTERNATIONAL COMMUNITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AG</td>\n",
       "      <td>1</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>AG</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253461018</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>USA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Hawaii, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USHI</td>\n",
       "      <td>21.10980</td>\n",
       "      <td>-157.53100</td>\n",
       "      <td>HI</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.philippinetimes.com/index.php/sid/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253461019</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>USA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Nevada, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USNV</td>\n",
       "      <td>38.41990</td>\n",
       "      <td>-117.12200</td>\n",
       "      <td>NV</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.theglobeandmail.com/life/health-and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>253461020</td>\n",
       "      <td>20030404</td>\n",
       "      <td>200304</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.2575</td>\n",
       "      <td>USA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USNY</td>\n",
       "      <td>42.14970</td>\n",
       "      <td>-74.93840</td>\n",
       "      <td>NY</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.theglobeandmail.com/life/health-and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253461021</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1955538</td>\n",
       "      <td>4</td>\n",
       "      <td>Brussels, Bruxelles-Capitale, Belgium</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE11</td>\n",
       "      <td>50.83330</td>\n",
       "      <td>4.33333</td>\n",
       "      <td>-1955538</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.channelnewsasia.com/news/world/us-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253461022</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.miamiherald.com/2013/04/01/3317988/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253461023</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>RQ</td>\n",
       "      <td>1</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>RQ</td>\n",
       "      <td>RQ</td>\n",
       "      <td>18.23590</td>\n",
       "      <td>-66.48380</td>\n",
       "      <td>RQ</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.ameinfo.com/takaud-makes-senior-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>253461024</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>CH</td>\n",
       "      <td>CH</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>CH</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.philippinetimes.com/index.php/sid/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>253461025</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>CH</td>\n",
       "      <td>CH</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>CH</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.panarmenian.net/eng/news/152303/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>253461026</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>236787</td>\n",
       "      <td>4</td>\n",
       "      <td>East Bay, India (general), India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN00</td>\n",
       "      <td>7.98333</td>\n",
       "      <td>93.40000</td>\n",
       "      <td>-2095397</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.contracostatimes.com/breaking-news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>253461027</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NI</td>\n",
       "      <td>4</td>\n",
       "      <td>East Bay, India (general), India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN00</td>\n",
       "      <td>7.98333</td>\n",
       "      <td>93.40000</td>\n",
       "      <td>-2095397</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.contracostatimes.com/breaking-news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>253461028</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NI</td>\n",
       "      <td>1</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NI</td>\n",
       "      <td>NI</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>NI</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.contracostatimes.com/breaking-news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>253461029</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2542793</td>\n",
       "      <td>4</td>\n",
       "      <td>Jobar, Dimashq, Syria</td>\n",
       "      <td>SY</td>\n",
       "      <td>SY13</td>\n",
       "      <td>33.52650</td>\n",
       "      <td>36.33540</td>\n",
       "      <td>-2542793</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.ynetnews.com/articles/0,7340,L-4362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>253461030</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-801546</td>\n",
       "      <td>4</td>\n",
       "      <td>Beirut, Beyrouth, Lebanon</td>\n",
       "      <td>LE</td>\n",
       "      <td>LE04</td>\n",
       "      <td>33.87190</td>\n",
       "      <td>35.50970</td>\n",
       "      <td>-801546</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.google.com/hostednews/ap/article/AL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>253461031</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.news.com.au/breaking-news/thinking-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>253461032</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2769132</td>\n",
       "      <td>4</td>\n",
       "      <td>Mingora, North-West Frontier, Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>PK03</td>\n",
       "      <td>34.77580</td>\n",
       "      <td>72.36250</td>\n",
       "      <td>-2769132</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.npr.org/2013/04/01/175706661/pakist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>253461033</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2604469</td>\n",
       "      <td>4</td>\n",
       "      <td>Nottingham, Nottingham, United Kingdom</td>\n",
       "      <td>UK</td>\n",
       "      <td>UKJ8</td>\n",
       "      <td>52.96670</td>\n",
       "      <td>-1.16667</td>\n",
       "      <td>-2604469</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.dailymail.co.uk/health/article-2302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>253461034</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1445327</td>\n",
       "      <td>4</td>\n",
       "      <td>Paris, RhôAlpes, France</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRB9</td>\n",
       "      <td>45.63330</td>\n",
       "      <td>5.73333</td>\n",
       "      <td>-1445327</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.miamiherald.com/2013/04/01/3317183/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>253461035</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1445327</td>\n",
       "      <td>4</td>\n",
       "      <td>Paris, RhôAlpes, France</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRB9</td>\n",
       "      <td>45.63330</td>\n",
       "      <td>5.73333</td>\n",
       "      <td>-1445327</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.nzherald.co.nz/world/news/article.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>253461036</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1188456</td>\n",
       "      <td>4</td>\n",
       "      <td>Labasa, Northern, Fiji</td>\n",
       "      <td>FJ</td>\n",
       "      <td>FJ03</td>\n",
       "      <td>-16.41670</td>\n",
       "      <td>179.38300</td>\n",
       "      <td>-1188456</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.fijitimes.com/story.aspx?id=229847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>253461037</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>CH</td>\n",
       "      <td>CH</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>CH</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://stream.wsj.com/story/latest-headlines/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>253461038</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-570760</td>\n",
       "      <td>4</td>\n",
       "      <td>Ottawa, Ontario, Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA08</td>\n",
       "      <td>45.41670</td>\n",
       "      <td>-75.70000</td>\n",
       "      <td>-570760</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.theglobeandmail.com/news/politics/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>253461039</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AG</td>\n",
       "      <td>1</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>AG</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>253461040</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AG</td>\n",
       "      <td>1</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>AG</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>253461041</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-797092</td>\n",
       "      <td>4</td>\n",
       "      <td>Jerusalem, Israel (general), Israel</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS00</td>\n",
       "      <td>31.76670</td>\n",
       "      <td>35.23330</td>\n",
       "      <td>-797092</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.b92.net//eng/news/world-article.php...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>253461042</td>\n",
       "      <td>20120401</td>\n",
       "      <td>201204</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012.2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NY</td>\n",
       "      <td>2</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USCA</td>\n",
       "      <td>36.17000</td>\n",
       "      <td>-119.74600</td>\n",
       "      <td>CA</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://uk.reuters.com/article/2013/04/01/uk-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27727</th>\n",
       "      <td>253488840</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-781545</td>\n",
       "      <td>4</td>\n",
       "      <td>Tel Aviv, Tel Aviv, Israel</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS05</td>\n",
       "      <td>32.06670</td>\n",
       "      <td>34.76670</td>\n",
       "      <td>-781545</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.haaretz.com/news/national/worst-san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27728</th>\n",
       "      <td>253488841</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762812</td>\n",
       "      <td>4</td>\n",
       "      <td>Delhi, Delhi, India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN07</td>\n",
       "      <td>28.66670</td>\n",
       "      <td>77.21670</td>\n",
       "      <td>-2094230</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/south-asia/pak-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27729</th>\n",
       "      <td>253488842</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>BEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Belgrade, Serbia (general),</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB00</td>\n",
       "      <td>44.81860</td>\n",
       "      <td>20.46810</td>\n",
       "      <td>-74897</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.b92.net//eng/news/politics-article....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27730</th>\n",
       "      <td>253488843</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>CVL</td>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.news.com.au/national-news/victoria/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27731</th>\n",
       "      <td>253488844</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>CYP</td>\n",
       "      <td>CYPRUS</td>\n",
       "      <td>CYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CY</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>CY</td>\n",
       "      <td>CY</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>CY</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bbc.co.uk/news/world-europe-2199827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27732</th>\n",
       "      <td>253488845</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>EDU</td>\n",
       "      <td>SCHOOL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27733</th>\n",
       "      <td>253488846</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>GOV</td>\n",
       "      <td>REGULATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.nzherald.co.nz/technology/news/arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27734</th>\n",
       "      <td>253488847</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>GOV</td>\n",
       "      <td>MINIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>CH</td>\n",
       "      <td>CH</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>CH</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/asian-lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27735</th>\n",
       "      <td>253488848</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>GOVEDU</td>\n",
       "      <td>EDUCATION MINIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Croke Park, Dublin City, Ireland</td>\n",
       "      <td>EI</td>\n",
       "      <td>EI33</td>\n",
       "      <td>53.36670</td>\n",
       "      <td>-6.25000</td>\n",
       "      <td>-1502118</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.breakingnews.ie/ireland/teachers-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27736</th>\n",
       "      <td>253488849</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>GOVEDU</td>\n",
       "      <td>EDUCATION MINIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1502118</td>\n",
       "      <td>4</td>\n",
       "      <td>Croke Park, Dublin City, Ireland</td>\n",
       "      <td>EI</td>\n",
       "      <td>EI33</td>\n",
       "      <td>53.36670</td>\n",
       "      <td>-6.25000</td>\n",
       "      <td>-1502118</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.breakingnews.ie/ireland/teachers-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27737</th>\n",
       "      <td>253488850</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>IDN</td>\n",
       "      <td>SPICE ISLANDS</td>\n",
       "      <td>IDN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Spice Islands, Maluku Utara, Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID29</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>128.00000</td>\n",
       "      <td>-2686482</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.csmonitor.com/World/Backchannels/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27738</th>\n",
       "      <td>253488851</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>IND</td>\n",
       "      <td>UTTARAKHAND</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27739</th>\n",
       "      <td>253488852</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>IND</td>\n",
       "      <td>NEW DELHI</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27740</th>\n",
       "      <td>253488853</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>INDGOV</td>\n",
       "      <td>UTTARAKHAND</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27741</th>\n",
       "      <td>253488854</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>INDGOV</td>\n",
       "      <td>UTTARAKHAND</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27742</th>\n",
       "      <td>253488855</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>INDGOV</td>\n",
       "      <td>UTTARAKHAND</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27743</th>\n",
       "      <td>253488856</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>INDGOV</td>\n",
       "      <td>UTTARAKHAND</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27744</th>\n",
       "      <td>253488857</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>IRL</td>\n",
       "      <td>GALWAY</td>\n",
       "      <td>IRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Wexford, Wexford, Ireland</td>\n",
       "      <td>EI</td>\n",
       "      <td>EI30</td>\n",
       "      <td>52.33420</td>\n",
       "      <td>-6.45750</td>\n",
       "      <td>-1506176</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.breakingnews.ie/ireland/teachers-un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>253488858</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>IRLGOVEDU</td>\n",
       "      <td>IRELAND</td>\n",
       "      <td>IRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Croke Park, Dublin City, Ireland</td>\n",
       "      <td>EI</td>\n",
       "      <td>EI33</td>\n",
       "      <td>53.36670</td>\n",
       "      <td>-6.25000</td>\n",
       "      <td>-1502118</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.breakingnews.ie/ireland/teachers-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27746</th>\n",
       "      <td>253488859</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>ISL</td>\n",
       "      <td>ICELAND</td>\n",
       "      <td>ISL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27747</th>\n",
       "      <td>253488860</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>ISLGOV</td>\n",
       "      <td>ICELAND</td>\n",
       "      <td>ISL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>IC</td>\n",
       "      <td>IC</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>-18.00000</td>\n",
       "      <td>IC</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/world/iceland-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>253488861</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>ISR</td>\n",
       "      <td>ISRAELI</td>\n",
       "      <td>ISR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Tel Aviv, Tel Aviv, Israel</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS05</td>\n",
       "      <td>32.06670</td>\n",
       "      <td>34.76670</td>\n",
       "      <td>-781545</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.haaretz.com/news/national/worst-san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27749</th>\n",
       "      <td>253488862</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>JUD</td>\n",
       "      <td>COUNSEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Delhi, Delhi, India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN07</td>\n",
       "      <td>28.66670</td>\n",
       "      <td>77.21670</td>\n",
       "      <td>-2094230</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.thehindu.com/news/national/delhi-hc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27750</th>\n",
       "      <td>253488863</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WORKER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>AG</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27751</th>\n",
       "      <td>253488864</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>MNCUSA</td>\n",
       "      <td>DISNEY</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-575268</td>\n",
       "      <td>4</td>\n",
       "      <td>Vancouver, British Columbia, Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA02</td>\n",
       "      <td>49.25000</td>\n",
       "      <td>-123.13300</td>\n",
       "      <td>-575268</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.theglobeandmail.com/arts/film/disne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27752</th>\n",
       "      <td>253488865</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>PAK</td>\n",
       "      <td>ISLAMABAD</td>\n",
       "      <td>PAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Islamabad, Islamabad, Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>PK08</td>\n",
       "      <td>33.70000</td>\n",
       "      <td>73.16670</td>\n",
       "      <td>-2762812</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://zeenews.india.com/news/south-asia/pak-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27753</th>\n",
       "      <td>253488866</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>SAU</td>\n",
       "      <td>SAUDI</td>\n",
       "      <td>SAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3093009</td>\n",
       "      <td>4</td>\n",
       "      <td>Riyadh, Ar Riya?, Saudi Arabia</td>\n",
       "      <td>SA</td>\n",
       "      <td>SA10</td>\n",
       "      <td>24.64080</td>\n",
       "      <td>46.77280</td>\n",
       "      <td>-3093009</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bna.bh/portal/en/news/554276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27754</th>\n",
       "      <td>253488867</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>SAUJUD</td>\n",
       "      <td>SAUDI</td>\n",
       "      <td>SAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3093009</td>\n",
       "      <td>4</td>\n",
       "      <td>Riyadh, Ar Riya?, Saudi Arabia</td>\n",
       "      <td>SA</td>\n",
       "      <td>SA10</td>\n",
       "      <td>24.64080</td>\n",
       "      <td>46.77280</td>\n",
       "      <td>-3093009</td>\n",
       "      <td>20130401</td>\n",
       "      <td>http://www.bna.bh/portal/en/news/554276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27755</th>\n",
       "      <td>253488868</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>SCGSRB</td>\n",
       "      <td>SERBIA</td>\n",
       "      <td>SRB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Tataouine, Tatawin, Tunisia</td>\n",
       "      <td>TS</td>\n",
       "      <td>TS34</td>\n",
       "      <td>32.92970</td>\n",
       "      <td>10.45180</td>\n",
       "      <td>-731465</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27756</th>\n",
       "      <td>253488869</td>\n",
       "      <td>20130402</td>\n",
       "      <td>201304</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013.2521</td>\n",
       "      <td>SCGSRB</td>\n",
       "      <td>SERBIA</td>\n",
       "      <td>SRB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3178548</td>\n",
       "      <td>4</td>\n",
       "      <td>Tataouine, Tatawin, Tunisia</td>\n",
       "      <td>TS</td>\n",
       "      <td>TS34</td>\n",
       "      <td>32.92970</td>\n",
       "      <td>10.45180</td>\n",
       "      <td>-731465</td>\n",
       "      <td>20130401</td>\n",
       "      <td>BBC Monitoring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27470 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GLOBALEVENTID   SQLDATE  MonthYear  Year  FractionDate Actor1Code  \\\n",
       "1          253461013  20030404     200304  2003     2003.2575        BUS   \n",
       "2          253461014  20030404     200304  2003     2003.2575        BUS   \n",
       "3          253461015  20030404     200304  2003     2003.2575        CVL   \n",
       "4          253461016  20030404     200304  2003     2003.2575        HLH   \n",
       "5          253461017  20030404     200304  2003     2003.2575        UIS   \n",
       "6          253461018  20030404     200304  2003     2003.2575        USA   \n",
       "7          253461019  20030404     200304  2003     2003.2575        USA   \n",
       "8          253461020  20030404     200304  2003     2003.2575        USA   \n",
       "9          253461021  20120401     201204  2012     2012.2493        NaN   \n",
       "10         253461022  20120401     201204  2012     2012.2493        NaN   \n",
       "11         253461023  20120401     201204  2012     2012.2493        NaN   \n",
       "12         253461024  20120401     201204  2012     2012.2493        NaN   \n",
       "13         253461025  20120401     201204  2012     2012.2493        NaN   \n",
       "14         253461026  20120401     201204  2012     2012.2493        NaN   \n",
       "15         253461027  20120401     201204  2012     2012.2493        NaN   \n",
       "16         253461028  20120401     201204  2012     2012.2493        NaN   \n",
       "17         253461029  20120401     201204  2012     2012.2493        NaN   \n",
       "18         253461030  20120401     201204  2012     2012.2493        NaN   \n",
       "19         253461031  20120401     201204  2012     2012.2493        NaN   \n",
       "20         253461032  20120401     201204  2012     2012.2493        NaN   \n",
       "21         253461033  20120401     201204  2012     2012.2493        NaN   \n",
       "22         253461034  20120401     201204  2012     2012.2493        NaN   \n",
       "23         253461035  20120401     201204  2012     2012.2493        NaN   \n",
       "24         253461036  20120401     201204  2012     2012.2493        NaN   \n",
       "25         253461037  20120401     201204  2012     2012.2493        NaN   \n",
       "26         253461038  20120401     201204  2012     2012.2493        NaN   \n",
       "27         253461039  20120401     201204  2012     2012.2493        NaN   \n",
       "28         253461040  20120401     201204  2012     2012.2493        NaN   \n",
       "29         253461041  20120401     201204  2012     2012.2493        NaN   \n",
       "30         253461042  20120401     201204  2012     2012.2493        NaN   \n",
       "...              ...       ...        ...   ...           ...        ...   \n",
       "27727      253488840  20130402     201304  2013     2013.2521        NaN   \n",
       "27728      253488841  20130402     201304  2013     2013.2521        NaN   \n",
       "27729      253488842  20130402     201304  2013     2013.2521        BEL   \n",
       "27730      253488843  20130402     201304  2013     2013.2521        CVL   \n",
       "27731      253488844  20130402     201304  2013     2013.2521        CYP   \n",
       "27732      253488845  20130402     201304  2013     2013.2521        EDU   \n",
       "27733      253488846  20130402     201304  2013     2013.2521        GOV   \n",
       "27734      253488847  20130402     201304  2013     2013.2521        GOV   \n",
       "27735      253488848  20130402     201304  2013     2013.2521     GOVEDU   \n",
       "27736      253488849  20130402     201304  2013     2013.2521     GOVEDU   \n",
       "27737      253488850  20130402     201304  2013     2013.2521        IDN   \n",
       "27738      253488851  20130402     201304  2013     2013.2521        IND   \n",
       "27739      253488852  20130402     201304  2013     2013.2521        IND   \n",
       "27740      253488853  20130402     201304  2013     2013.2521     INDGOV   \n",
       "27741      253488854  20130402     201304  2013     2013.2521     INDGOV   \n",
       "27742      253488855  20130402     201304  2013     2013.2521     INDGOV   \n",
       "27743      253488856  20130402     201304  2013     2013.2521     INDGOV   \n",
       "27744      253488857  20130402     201304  2013     2013.2521        IRL   \n",
       "27745      253488858  20130402     201304  2013     2013.2521  IRLGOVEDU   \n",
       "27746      253488859  20130402     201304  2013     2013.2521        ISL   \n",
       "27747      253488860  20130402     201304  2013     2013.2521     ISLGOV   \n",
       "27748      253488861  20130402     201304  2013     2013.2521        ISR   \n",
       "27749      253488862  20130402     201304  2013     2013.2521        JUD   \n",
       "27750      253488863  20130402     201304  2013     2013.2521        LAB   \n",
       "27751      253488864  20130402     201304  2013     2013.2521     MNCUSA   \n",
       "27752      253488865  20130402     201304  2013     2013.2521        PAK   \n",
       "27753      253488866  20130402     201304  2013     2013.2521        SAU   \n",
       "27754      253488867  20130402     201304  2013     2013.2521     SAUJUD   \n",
       "27755      253488868  20130402     201304  2013     2013.2521     SCGSRB   \n",
       "27756      253488869  20130402     201304  2013     2013.2521     SCGSRB   \n",
       "\n",
       "                        Actor1Name Actor1CountryCode Actor1KnownGroupCode  \\\n",
       "1                       SHOP OWNER               NaN                  NaN   \n",
       "2                       SHOP OWNER               NaN                  NaN   \n",
       "3                          MIGRANT               NaN                  NaN   \n",
       "4                           DOCTOR               NaN                  NaN   \n",
       "5      THE INTERNATIONAL COMMUNITY               NaN                  NaN   \n",
       "6                         NEW YORK               USA                  NaN   \n",
       "7                         NEW YORK               USA                  NaN   \n",
       "8                         NEW YORK               USA                  NaN   \n",
       "9                              NaN               NaN                  NaN   \n",
       "10                             NaN               NaN                  NaN   \n",
       "11                             NaN               NaN                  NaN   \n",
       "12                             NaN               NaN                  NaN   \n",
       "13                             NaN               NaN                  NaN   \n",
       "14                             NaN               NaN                  NaN   \n",
       "15                             NaN               NaN                  NaN   \n",
       "16                             NaN               NaN                  NaN   \n",
       "17                             NaN               NaN                  NaN   \n",
       "18                             NaN               NaN                  NaN   \n",
       "19                             NaN               NaN                  NaN   \n",
       "20                             NaN               NaN                  NaN   \n",
       "21                             NaN               NaN                  NaN   \n",
       "22                             NaN               NaN                  NaN   \n",
       "23                             NaN               NaN                  NaN   \n",
       "24                             NaN               NaN                  NaN   \n",
       "25                             NaN               NaN                  NaN   \n",
       "26                             NaN               NaN                  NaN   \n",
       "27                             NaN               NaN                  NaN   \n",
       "28                             NaN               NaN                  NaN   \n",
       "29                             NaN               NaN                  NaN   \n",
       "30                             NaN               NaN                  NaN   \n",
       "...                            ...               ...                  ...   \n",
       "27727                          NaN               NaN                  NaN   \n",
       "27728                          NaN               NaN                  NaN   \n",
       "27729                     BRUSSELS               BEL                  NaN   \n",
       "27730                    COMMUNITY               NaN                  NaN   \n",
       "27731                       CYPRUS               CYP                  NaN   \n",
       "27732                       SCHOOL               NaN                  NaN   \n",
       "27733                    REGULATOR               NaN                  NaN   \n",
       "27734                      MINIST                NaN                  NaN   \n",
       "27735            EDUCATION MINIST                NaN                  NaN   \n",
       "27736            EDUCATION MINIST                NaN                  NaN   \n",
       "27737                SPICE ISLANDS               IDN                  NaN   \n",
       "27738                  UTTARAKHAND               IND                  NaN   \n",
       "27739                    NEW DELHI               IND                  NaN   \n",
       "27740                  UTTARAKHAND               IND                  NaN   \n",
       "27741                  UTTARAKHAND               IND                  NaN   \n",
       "27742                  UTTARAKHAND               IND                  NaN   \n",
       "27743                  UTTARAKHAND               IND                  NaN   \n",
       "27744                       GALWAY               IRL                  NaN   \n",
       "27745                      IRELAND               IRL                  NaN   \n",
       "27746                      ICELAND               ISL                  NaN   \n",
       "27747                      ICELAND               ISL                  NaN   \n",
       "27748                      ISRAELI               ISR                  NaN   \n",
       "27749                      COUNSEL               NaN                  NaN   \n",
       "27750                       WORKER               NaN                  NaN   \n",
       "27751                       DISNEY               USA                  NaN   \n",
       "27752                    ISLAMABAD               PAK                  NaN   \n",
       "27753                        SAUDI               SAU                  NaN   \n",
       "27754                        SAUDI               SAU                  NaN   \n",
       "27755                       SERBIA               SRB                  NaN   \n",
       "27756                       SERBIA               SRB                  NaN   \n",
       "\n",
       "      Actor1EthnicCode                        ...                          \\\n",
       "1                  NaN                        ...                           \n",
       "2                  NaN                        ...                           \n",
       "3                  NaN                        ...                           \n",
       "4                  NaN                        ...                           \n",
       "5                  NaN                        ...                           \n",
       "6                  NaN                        ...                           \n",
       "7                  NaN                        ...                           \n",
       "8                  NaN                        ...                           \n",
       "9                  NaN                        ...                           \n",
       "10                 NaN                        ...                           \n",
       "11                 NaN                        ...                           \n",
       "12                 NaN                        ...                           \n",
       "13                 NaN                        ...                           \n",
       "14                 NaN                        ...                           \n",
       "15                 NaN                        ...                           \n",
       "16                 NaN                        ...                           \n",
       "17                 NaN                        ...                           \n",
       "18                 NaN                        ...                           \n",
       "19                 NaN                        ...                           \n",
       "20                 NaN                        ...                           \n",
       "21                 NaN                        ...                           \n",
       "22                 NaN                        ...                           \n",
       "23                 NaN                        ...                           \n",
       "24                 NaN                        ...                           \n",
       "25                 NaN                        ...                           \n",
       "26                 NaN                        ...                           \n",
       "27                 NaN                        ...                           \n",
       "28                 NaN                        ...                           \n",
       "29                 NaN                        ...                           \n",
       "30                 NaN                        ...                           \n",
       "...                ...                        ...                           \n",
       "27727              NaN                        ...                           \n",
       "27728              NaN                        ...                           \n",
       "27729              NaN                        ...                           \n",
       "27730              NaN                        ...                           \n",
       "27731              NaN                        ...                           \n",
       "27732              NaN                        ...                           \n",
       "27733              NaN                        ...                           \n",
       "27734              NaN                        ...                           \n",
       "27735              NaN                        ...                           \n",
       "27736              NaN                        ...                           \n",
       "27737              NaN                        ...                           \n",
       "27738              NaN                        ...                           \n",
       "27739              NaN                        ...                           \n",
       "27740              NaN                        ...                           \n",
       "27741              NaN                        ...                           \n",
       "27742              NaN                        ...                           \n",
       "27743              NaN                        ...                           \n",
       "27744              NaN                        ...                           \n",
       "27745              NaN                        ...                           \n",
       "27746              NaN                        ...                           \n",
       "27747              NaN                        ...                           \n",
       "27748              NaN                        ...                           \n",
       "27749              NaN                        ...                           \n",
       "27750              NaN                        ...                           \n",
       "27751              NaN                        ...                           \n",
       "27752              NaN                        ...                           \n",
       "27753              NaN                        ...                           \n",
       "27754              NaN                        ...                           \n",
       "27755              NaN                        ...                           \n",
       "27756              NaN                        ...                           \n",
       "\n",
       "      Actor2Geo_FeatureID ActionGeo_Type  \\\n",
       "1                -1354145              4   \n",
       "2                -1354454              4   \n",
       "3                      AS              1   \n",
       "4                     NaN              2   \n",
       "5                      AG              1   \n",
       "6                     NaN              2   \n",
       "7                     NaN              2   \n",
       "8                     NaN              2   \n",
       "9                -1955538              4   \n",
       "10                    NaN              0   \n",
       "11                     RQ              1   \n",
       "12                     CH              1   \n",
       "13                     CH              1   \n",
       "14                 236787              4   \n",
       "15                     NI              4   \n",
       "16                     NI              1   \n",
       "17               -2542793              4   \n",
       "18                -801546              4   \n",
       "19                    NaN              0   \n",
       "20               -2769132              4   \n",
       "21               -2604469              4   \n",
       "22               -1445327              4   \n",
       "23               -1445327              4   \n",
       "24               -1188456              4   \n",
       "25                     CH              1   \n",
       "26                -570760              4   \n",
       "27                     AG              1   \n",
       "28                     AG              1   \n",
       "29                -797092              4   \n",
       "30                     NY              2   \n",
       "...                   ...            ...   \n",
       "27727             -781545              4   \n",
       "27728            -2762812              4   \n",
       "27729                 NaN              4   \n",
       "27730                 NaN              0   \n",
       "27731                  CY              1   \n",
       "27732                  IC              1   \n",
       "27733                 NaN              0   \n",
       "27734                  CH              1   \n",
       "27735                 NaN              4   \n",
       "27736            -1502118              4   \n",
       "27737                 NaN              4   \n",
       "27738                  IC              1   \n",
       "27739                 NaN              0   \n",
       "27740                  IC              1   \n",
       "27741                  IC              1   \n",
       "27742                  IC              1   \n",
       "27743                  IC              1   \n",
       "27744                 NaN              4   \n",
       "27745                 NaN              4   \n",
       "27746                  IC              1   \n",
       "27747                  IC              1   \n",
       "27748                 NaN              4   \n",
       "27749                 NaN              4   \n",
       "27750                 NaN              1   \n",
       "27751             -575268              4   \n",
       "27752                 NaN              4   \n",
       "27753            -3093009              4   \n",
       "27754            -3093009              4   \n",
       "27755                 NaN              4   \n",
       "27756            -3178548              4   \n",
       "\n",
       "                             ActionGeo_FullName ActionGeo_CountryCode  \\\n",
       "1      Tai Hang, Hong Kong (general), Hong Kong                    HK   \n",
       "2      Tai Hang, Hong Kong (general), Hong Kong                    HK   \n",
       "3                                     Australia                    AS   \n",
       "4                         Nevada, United States                    US   \n",
       "5                                       Algeria                    AG   \n",
       "6                         Hawaii, United States                    US   \n",
       "7                         Nevada, United States                    US   \n",
       "8                       New York, United States                    US   \n",
       "9         Brussels, Bruxelles-Capitale, Belgium                    BE   \n",
       "10                                          NaN                   NaN   \n",
       "11                                  Puerto Rico                    RQ   \n",
       "12                                        China                    CH   \n",
       "13                                        China                    CH   \n",
       "14             East Bay, India (general), India                    IN   \n",
       "15             East Bay, India (general), India                    IN   \n",
       "16                                      Nigeria                    NI   \n",
       "17                        Jobar, Dimashq, Syria                    SY   \n",
       "18                    Beirut, Beyrouth, Lebanon                    LE   \n",
       "19                                          NaN                   NaN   \n",
       "20       Mingora, North-West Frontier, Pakistan                    PK   \n",
       "21       Nottingham, Nottingham, United Kingdom                    UK   \n",
       "22                      Paris, RhôAlpes, France                    FR   \n",
       "23                      Paris, RhôAlpes, France                    FR   \n",
       "24                       Labasa, Northern, Fiji                    FJ   \n",
       "25                                        China                    CH   \n",
       "26                      Ottawa, Ontario, Canada                    CA   \n",
       "27                                      Algeria                    AG   \n",
       "28                                      Algeria                    AG   \n",
       "29          Jerusalem, Israel (general), Israel                    IS   \n",
       "30                    California, United States                    US   \n",
       "...                                         ...                   ...   \n",
       "27727                Tel Aviv, Tel Aviv, Israel                    IS   \n",
       "27728                       Delhi, Delhi, India                    IN   \n",
       "27729              Belgrade, Serbia (general),                     RB   \n",
       "27730                                       NaN                   NaN   \n",
       "27731                                    Cyprus                    CY   \n",
       "27732                                   Iceland                    IC   \n",
       "27733                                       NaN                   NaN   \n",
       "27734                                     China                    CH   \n",
       "27735          Croke Park, Dublin City, Ireland                    EI   \n",
       "27736          Croke Park, Dublin City, Ireland                    EI   \n",
       "27737    Spice Islands, Maluku Utara, Indonesia                    ID   \n",
       "27738                                   Iceland                    IC   \n",
       "27739                                       NaN                   NaN   \n",
       "27740                                   Iceland                    IC   \n",
       "27741                                   Iceland                    IC   \n",
       "27742                                   Iceland                    IC   \n",
       "27743                                   Iceland                    IC   \n",
       "27744                 Wexford, Wexford, Ireland                    EI   \n",
       "27745          Croke Park, Dublin City, Ireland                    EI   \n",
       "27746                                   Iceland                    IC   \n",
       "27747                                   Iceland                    IC   \n",
       "27748                Tel Aviv, Tel Aviv, Israel                    IS   \n",
       "27749                       Delhi, Delhi, India                    IN   \n",
       "27750                                   Algeria                    AG   \n",
       "27751       Vancouver, British Columbia, Canada                    CA   \n",
       "27752            Islamabad, Islamabad, Pakistan                    PK   \n",
       "27753            Riyadh, Ar Riya?, Saudi Arabia                    SA   \n",
       "27754            Riyadh, Ar Riya?, Saudi Arabia                    SA   \n",
       "27755               Tataouine, Tatawin, Tunisia                    TS   \n",
       "27756               Tataouine, Tatawin, Tunisia                    TS   \n",
       "\n",
       "      ActionGeo_ADM1Code ActionGeo_Lat ActionGeo_Long ActionGeo_FeatureID  \\\n",
       "1                   HK00      22.46670      114.15000            -1354145   \n",
       "2                   HK00      22.46670      114.15000            -1354145   \n",
       "3                     AS     -27.00000      133.00000                  AS   \n",
       "4                   USNV      38.41990     -117.12200                  NV   \n",
       "5                     AG      28.00000        3.00000                  AG   \n",
       "6                   USHI      21.10980     -157.53100                  HI   \n",
       "7                   USNV      38.41990     -117.12200                  NV   \n",
       "8                   USNY      42.14970      -74.93840                  NY   \n",
       "9                   BE11      50.83330        4.33333            -1955538   \n",
       "10                   NaN           NaN            NaN                 NaN   \n",
       "11                    RQ      18.23590      -66.48380                  RQ   \n",
       "12                    CH      35.00000      105.00000                  CH   \n",
       "13                    CH      35.00000      105.00000                  CH   \n",
       "14                  IN00       7.98333       93.40000            -2095397   \n",
       "15                  IN00       7.98333       93.40000            -2095397   \n",
       "16                    NI      10.00000        8.00000                  NI   \n",
       "17                  SY13      33.52650       36.33540            -2542793   \n",
       "18                  LE04      33.87190       35.50970             -801546   \n",
       "19                   NaN           NaN            NaN                 NaN   \n",
       "20                  PK03      34.77580       72.36250            -2769132   \n",
       "21                  UKJ8      52.96670       -1.16667            -2604469   \n",
       "22                  FRB9      45.63330        5.73333            -1445327   \n",
       "23                  FRB9      45.63330        5.73333            -1445327   \n",
       "24                  FJ03     -16.41670      179.38300            -1188456   \n",
       "25                    CH      35.00000      105.00000                  CH   \n",
       "26                  CA08      45.41670      -75.70000             -570760   \n",
       "27                    AG      28.00000        3.00000                  AG   \n",
       "28                    AG      28.00000        3.00000                  AG   \n",
       "29                  IS00      31.76670       35.23330             -797092   \n",
       "30                  USCA      36.17000     -119.74600                  CA   \n",
       "...                  ...           ...            ...                 ...   \n",
       "27727               IS05      32.06670       34.76670             -781545   \n",
       "27728               IN07      28.66670       77.21670            -2094230   \n",
       "27729               RB00      44.81860       20.46810              -74897   \n",
       "27730                NaN           NaN            NaN                 NaN   \n",
       "27731                 CY      35.00000       33.00000                  CY   \n",
       "27732                 IC      65.00000      -18.00000                  IC   \n",
       "27733                NaN           NaN            NaN                 NaN   \n",
       "27734                 CH      35.00000      105.00000                  CH   \n",
       "27735               EI33      53.36670       -6.25000            -1502118   \n",
       "27736               EI33      53.36670       -6.25000            -1502118   \n",
       "27737               ID29      -2.00000      128.00000            -2686482   \n",
       "27738                 IC      65.00000      -18.00000                  IC   \n",
       "27739                NaN           NaN            NaN                 NaN   \n",
       "27740                 IC      65.00000      -18.00000                  IC   \n",
       "27741                 IC      65.00000      -18.00000                  IC   \n",
       "27742                 IC      65.00000      -18.00000                  IC   \n",
       "27743                 IC      65.00000      -18.00000                  IC   \n",
       "27744               EI30      52.33420       -6.45750            -1506176   \n",
       "27745               EI33      53.36670       -6.25000            -1502118   \n",
       "27746                 IC      65.00000      -18.00000                  IC   \n",
       "27747                 IC      65.00000      -18.00000                  IC   \n",
       "27748               IS05      32.06670       34.76670             -781545   \n",
       "27749               IN07      28.66670       77.21670            -2094230   \n",
       "27750                 AG      28.00000        3.00000                  AG   \n",
       "27751               CA02      49.25000     -123.13300             -575268   \n",
       "27752               PK08      33.70000       73.16670            -2762812   \n",
       "27753               SA10      24.64080       46.77280            -3093009   \n",
       "27754               SA10      24.64080       46.77280            -3093009   \n",
       "27755               TS34      32.92970       10.45180             -731465   \n",
       "27756               TS34      32.92970       10.45180             -731465   \n",
       "\n",
       "      DATEADDED                                          SOURCEURL  \n",
       "1      20130401  http://www.bloomberg.com/news/2013-04-01/hong-...  \n",
       "2      20130401  http://www.bloomberg.com/news/2013-04-01/hong-...  \n",
       "3      20130401  http://www.bangkokpost.com/breakingnews/343522...  \n",
       "4      20130401   http://www.startribune.com/nation/200818961.html  \n",
       "5      20130401                                     BBC Monitoring  \n",
       "6      20130401  http://www.philippinetimes.com/index.php/sid/2...  \n",
       "7      20130401  http://www.theglobeandmail.com/life/health-and...  \n",
       "8      20130401  http://www.theglobeandmail.com/life/health-and...  \n",
       "9      20130401  http://www.channelnewsasia.com/news/world/us-u...  \n",
       "10     20130401  http://www.miamiherald.com/2013/04/01/3317988/...  \n",
       "11     20130401  http://www.ameinfo.com/takaud-makes-senior-man...  \n",
       "12     20130401  http://www.philippinetimes.com/index.php/sid/2...  \n",
       "13     20130401        http://www.panarmenian.net/eng/news/152303/  \n",
       "14     20130401  http://www.contracostatimes.com/breaking-news/...  \n",
       "15     20130401  http://www.contracostatimes.com/breaking-news/...  \n",
       "16     20130401  http://www.contracostatimes.com/breaking-news/...  \n",
       "17     20130401  http://www.ynetnews.com/articles/0,7340,L-4362...  \n",
       "18     20130401  http://www.google.com/hostednews/ap/article/AL...  \n",
       "19     20130401  http://www.news.com.au/breaking-news/thinking-...  \n",
       "20     20130401  http://www.npr.org/2013/04/01/175706661/pakist...  \n",
       "21     20130401  http://www.dailymail.co.uk/health/article-2302...  \n",
       "22     20130401  http://www.miamiherald.com/2013/04/01/3317183/...  \n",
       "23     20130401  http://www.nzherald.co.nz/world/news/article.c...  \n",
       "24     20130401      http://www.fijitimes.com/story.aspx?id=229847  \n",
       "25     20130401  http://stream.wsj.com/story/latest-headlines/S...  \n",
       "26     20130401  http://www.theglobeandmail.com/news/politics/d...  \n",
       "27     20130401                                     BBC Monitoring  \n",
       "28     20130401                                     BBC Monitoring  \n",
       "29     20130401  http://www.b92.net//eng/news/world-article.php...  \n",
       "30     20130401  http://uk.reuters.com/article/2013/04/01/uk-sa...  \n",
       "...         ...                                                ...  \n",
       "27727  20130401  http://www.haaretz.com/news/national/worst-san...  \n",
       "27728  20130401  http://zeenews.india.com/news/south-asia/pak-y...  \n",
       "27729  20130401  http://www.b92.net//eng/news/politics-article....  \n",
       "27730  20130401  http://www.news.com.au/national-news/victoria/...  \n",
       "27731  20130401  http://www.bbc.co.uk/news/world-europe-2199827...  \n",
       "27732  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27733  20130401  http://www.nzherald.co.nz/technology/news/arti...  \n",
       "27734  20130401  http://zeenews.india.com/news/world/asian-lang...  \n",
       "27735  20130401  http://www.breakingnews.ie/ireland/teachers-an...  \n",
       "27736  20130401  http://www.breakingnews.ie/ireland/teachers-an...  \n",
       "27737  20130401  http://www.csmonitor.com/World/Backchannels/20...  \n",
       "27738  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27739  20130401  http://economictimes.indiatimes.com/news/econo...  \n",
       "27740  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27741  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27742  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27743  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27744  20130401  http://www.breakingnews.ie/ireland/teachers-un...  \n",
       "27745  20130401  http://www.breakingnews.ie/ireland/teachers-an...  \n",
       "27746  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27747  20130401  http://zeenews.india.com/news/world/iceland-pr...  \n",
       "27748  20130401  http://www.haaretz.com/news/national/worst-san...  \n",
       "27749  20130401  http://www.thehindu.com/news/national/delhi-hc...  \n",
       "27750  20130401                                     BBC Monitoring  \n",
       "27751  20130401  http://www.theglobeandmail.com/arts/film/disne...  \n",
       "27752  20130401  http://zeenews.india.com/news/south-asia/pak-y...  \n",
       "27753  20130401            http://www.bna.bh/portal/en/news/554276  \n",
       "27754  20130401            http://www.bna.bh/portal/en/news/554276  \n",
       "27755  20130401                                     BBC Monitoring  \n",
       "27756  20130401                                     BBC Monitoring  \n",
       "\n",
       "[27470 rows x 58 columns]"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.drop(droppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.rte.ie/news/2013/0401/379281-india-drug-patent-novartis/'"
      ]
     },
     "execution_count": 1206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_url[0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out different regressors on the data, no luck so far :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model=LogisticRegression(penalty='l2', C=1.) #, dual=False, tol=0.0001,, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "#model=RandomForestClassifier(n_estimators=10,max_features=4000,max_depth=5)#,max_features=7000)\n",
    "#model=AdaBoostClassifier(n_estimators=20)\n",
    "#model=MLPClassifier(activation='logistic',hidden_layer_sizes=(100,10,5))\n",
    "#model=KNeighborsClassifier(n_neighbors=15)\n",
    "model=SVC(C=.8,kernel='poly')\n",
    "model.fit(x_tfidf_class_trainval,y_tfidf_class_trainval)\n",
    "#model.fit(x_bow_class_trainval,y_bow_class_trainval)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
